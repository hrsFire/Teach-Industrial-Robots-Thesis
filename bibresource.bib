@misc{industrieroboter_2020,
	title = {Industrieroboter},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://de.wikipedia.org/w/index.php?title=Industrieroboter&oldid=199907434},
	abstract = {Ein Industrieroboter (IR, auch: Industrieller Manipulator) ist eine universelle, programmierbare Maschine zur Handhabung, Montage oder Bearbeitung von Werkstücken. Diese Roboter sind für den Einsatz im industriellen Umfeld konzipiert (z. B. Automobilfertigung). Sie gehören in die Maschinenbau-Disziplin Automatisierungstechnik. Der Industrieroboter besteht im Allgemeinen aus dem Manipulator (Roboterarm), der Steuerung und einem Effektor (Werkzeug, Greifer etc.). Oft werden Roboter auch mit verschiedenen Sensoren ausgerüstet. Einmal programmiert ist die Maschine in der Lage, einen Arbeitsablauf autonom durchzuführen, oder die Ausführung der Aufgabe abhängig von Sensorinformationen in Grenzen zu variieren.},
	language = {de},
	urldate = {2020-06-01},
	journal = {Wikipedia},
	month = may,
	year = {2020},
	note = {Page Version ID: 199907434}
}

@book{hagele_aufbau_2006,
	address = {Berlin, Heidelberg},
	series = {{VDI}-{Buch}},
	title = {Aufbau von {Industrierobotern}},
	isbn = {978-3-540-34823-8},
	language = {de},
	publisher = {Springer},
	author = {Hägele, Martin and Schäfer, Timo},
	editor = {Gevatter, Hans-Jürgen and Grünhaupt, Ulrich},
	year = {2006},
	doi = {10.1007/3-540-34823-9_27},
	pages = {743--744}
}

@book{pott_industrielle_2019,
	title = {Industrielle {Robotersysteme}: {Entscheiderwissen} für die {Planung} und {Umsetzung} wirtschaftlicher {Roboterlösungen}},
	isbn = {978-3-658-25344-8},
	shorttitle = {Industrielle {Robotersysteme}},
	abstract = {Dieses Buch bietet eine Einführung in die Grundlagen des industriellen Robotereinsatzes und vermittelt Praxiswissen im Hinblick auf Planung, Umsetzung und Betrieb von Robotersystemen. Roboter haben sich als zuverlässige Werkzeuge in der Automatisierung bewährt. Sie sind in vielen Industriebereichen für die wirtschaftliche Produktion unentbehrlich. Die erweiterten Einsatzmöglichkeiten verursachen allerdings auch einen erheblichen Integrationsbedarf auf dem Weg vom »nackten« Roboter zu einer maßgeschneiderten Roboterlösung. Zur Auswahl der passenden Roboterlösung und zur effektiven Kommunikation mit Lieferanten und Kunden sind technisches Basiswissen, die Grundbegriffe der Robotik und ein umfassender Marktüberblick unverzichtbar. Die Autoren vermitteln praxisnah die notwendigen Grundlagen, um informierte Entscheidungen bei der Umsetzung von Robotersystemen zu treffen.},
	language = {de},
	publisher = {Springer Vieweg},
	author = {Pott, Andreas and Dietz, Thomas},
	year = {2019},
	doi = {10.1007/978-3-658-25345-5}
}

@misc{genauigkeit_nodate,
	title = {Genauigkeit, {Wiederholgenauigkeit} und {Auflösung}},
	url = {https://www.pfeiffer-vacuum.com/de/know-how/mechanische-komponenten-im-vakuum/manipulatoren-und-mechanische-durchfuehrungen/genauigkeit-wiederholgenauigkeit-und-aufloesung/},
	urldate = {2020-06-02}
}

@misc{prazision_nodate,
	title = {Präzision und {Wiederholgenauigkeit}},
	url = {https://www.vision-doctor.com/wiederholgenauigkeit.html},
	urldate = {2020-06-02}
}

@misc{teach-technik_2020,
	title = {Teach-in ({Technik})},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://de.wikipedia.org/w/index.php?title=Teach-in_(Technik)&oldid=197654136},
	abstract = {Teach-in (engl., etwa: „Einlernen“; auch: Teachen) bezeichnet ein Verfahren zur Programmierung eines Roboters. Dazu fährt der Programmierer als Tutor den Roboter mit einer Steuerkonsole in die gewünschte Position. Alle auf diesem Weg erreichten Koordinaten (Punkte) werden in der Steuerung gespeichert. Dieser Schritt wird so oft und lange wiederholt, bis ein gesamter Arbeitszyklus einmal durchlaufen ist.
Der Programmablauf besteht darin, dass der Roboter alle gespeicherten Punkte autonom anfährt. Für die Bewegung zwischen den einzelnen Punkten können Parameter eingegeben werden. So sind die Geschwindigkeit und die Beschleunigung einstellbar, bei einigen Robotern ist auch eine Angabe der notwendigen Genauigkeit möglich.},
	language = {de},
	urldate = {2020-06-04},
	journal = {Wikipedia},
	month = mar,
	year = {2020},
	note = {Page Version ID: 197654136}
}

@article{biggs_survey_nodate,
	title = {A {Survey} of {Robot} {Programming} {Systems}},
	abstract = {Robots have become signiﬁcantly more powerful and intelligent over the last decade, and are moving in to more service oriented roles. As a result robots will more often be used by people with minimal technical skills and so there is a need for easier to use and more ﬂexible programming systems. This paper reviews the current state of the art in robot programming systems. A distinction is made between manual and automatic programming systems. Manual systems require the user/programmer to create the robot program directly, by hand, while automatic systems generate a robot program as a result of interaction between the robot and the human; there are a variety of methods including learning, programming by demonstration and instructive systems.},
	language = {en},
	author = {Biggs, Geoﬀrey and MacDonald, Bruce},
	pages = {5}
}

@book{prassler_advances_2004,
	title = {Advances in {Human}-{Robot} {Interaction}},
	isbn = {978-3-540-23211-7},
	abstract = {"Advances in Human-Robot Interaction" provides a unique collection of recent research in human-robot interaction. It covers the basic important research areas ranging from multi-modal interfaces, interpretation, interaction, learning, or motion coordination to topics such as physical interaction, systems, and architectures. The book addresses key issues of human-robot interaction concerned with perception, modelling, control, planning and cognition, covering a wide spectrum of applications. This includes interaction and communication with robots in manufacturing environments and the collaboration and co-existence with assistive robots in domestic environments. Among the presented examples are a robotic bartender, a new programming paradigm for a cleaning robot, or an approach to interactive teaching of a robot assistant in manufacturing environment. This carefully edited book reports on contributions from leading German academic institutions and industrial companies brought together within MORPHA, a 4 year project on interaction and communication between humans and anthropomorphic robot assistants.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Prassler, Erwin and Lawitzky, Gisbert and Stopp, Andreas and Grunwald, Gerhard and Hägele, Martin and Dillmann, Rüdiger and Iossifidis, Ioannis},
	month = oct,
	year = {2004},
	keywords = {Computers / Intelligence (AI) \& Semantics, Language Arts \& Disciplines / Library \& Information Science / General, Science / System Theory, Technology \& Engineering / Automation, Technology \& Engineering / General, Technology \& Engineering / Industrial Engineering, Technology \& Engineering / Machinery, Technology \& Engineering / Manufacturing, Technology \& Engineering / Power Resources / General}
}

@book{nof_handbook_1999,
	title = {Handbook of {Industrial} {Robotics}},
	isbn = {978-0-471-17783-8},
	abstract = {About the Handbook of Industrial Robotics, Second Edition:  "Once again, the Handbook of Industrial Robotics, in its Second Edition, explains the good ideas and knowledge that are needed for solutions." -Christopher B. Galvin, Chief Executive Officer, Motorola, Inc.  "The material covered in this Handbook reflects the new generation of robotics developments. It is a powerful educational resource for students, engineers, and managers, written by a leading team of robotics experts." - Yukio Hasegawa, Professor Emeritus, Waseda University, Japan.  "The Second Edition of the Handbook of Industrial Robotics organizes and systematizes the current expertise of industrial robotics and its forthcoming capabilities. These efforts are critical to solve the underlying problems of industry. This continuation is a source of power. I believe this Handbook will stimulate those who are concerned with industrial robots, and motivate them to be great contributors to the progress of industrial robotics." -Hiroshi Okuda, President, Toyota Motor Corporation.  "This Handbook describes very well the available and emerging robotics capabilities. It is a most comprehensive guide, including valuable information for both the providers and consumers of creative robotics applications." -Donald A. Vincent, Executive Vice President, Robotic Industries Association  120 leading experts from twelve countries have participated in creating this Second Edition of the Handbook of Industrial Robotics. Of its 66 chapters, 33 are new, covering important new topics in the theory, design, control, and applications of robotics. Other key features include a larger glossary of robotics terminology with over 800 terms and a CD-ROM that vividly conveys the colorful motions and intelligence of robotics. With contributions from the most prominent names in robotics worldwide, the Handbook remains the essential resource on all aspects of this complex subject.},
	language = {en},
	publisher = {John Wiley \& Sons},
	author = {Nof, Shimon Y.},
	month = mar,
	year = {1999},
	keywords = {Technology \& Engineering / General, Technology \& Engineering / Industrial Engineering},
	pages = {341--344}
}

@misc{programengif_nodate,
	title = {{programEN}.gif ({GIF}-{Grafik}, 500 × 243 {Pixel})},
	url = {http://www.machinery-export.com/de/roboter/abb/img/programEN.gif},
	urldate = {2020-06-04}
}

@misc{dead_man_switch_2020,
	title = {Dead man's switch},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Dead_man%27s_switch&oldid=960453369},
	abstract = {A dead man's switch (for other names, see alternative names) is a switch that is designed to be activated or deactivated if the human operator becomes incapacitated, such as through death, loss of consciousness, or being bodily removed from control. Originally applied to switches on a vehicle or machine, it has since come to be used to describe other intangible uses like in computer software.
These switches are usually used as a form of fail-safe where they stop a machine with no operator from a potentially dangerous action or incapacitate a device as a result of accident, malfunction, or misuse. They are common in such applications in locomotives, aircraft refuelling, freight elevators, lawn mowers, tractors, personal watercraft, outboard motors, chainsaws, snowblowers, tread machines, snowmobiles, amusement rides, and many medical imaging devices. On some machines, these switches merely bring the machines back to a safe state, such as reducing the throttle to idle or applying brakes while leaving the machines still running and ready to resume normal operation once control is reestablished.
Dead man's switches are not always used to stop machines and prevent harm. These switches can also be used as a fail-deadly. A spring-operated switch can also be used to complete a circuit when it is no longer held down. This means that a dead man's switch may be used to activate a harmful device, such as a bomb or IED. The user holds down a switch of some sort in their hand which arms the device. The device will activate when the switch is released, so that if the user is knocked out or killed while holding the switch, the bomb will detonate. The Special Weapons Emergency Separation System is an application of this concept in the field of nuclear weapons. A more extreme version is Russia's Dead Hand program, which allows for automatic launch of nuclear missiles should a number of conditions be met, even if all Russian leadership were to be killed.
A similar concept is the handwritten letters of last resort from the Prime Minister of the United Kingdom to the commanding officers of the four British ballistic missile submarines. They contain orders on what action to take if the British government were destroyed in a nuclear attack. After a prime minister leaves office the letters are destroyed unopened.
This concept has been employed with computer data, where sensitive information has been previously encrypted and released to the public, and the "switch" is the release of the decryption key, as with WikiLeaks' "insurance files".},
	language = {en},
	urldate = {2020-06-04},
	journal = {Wikipedia},
	month = jun,
	year = {2020},
	note = {Page Version ID: 960453369}
}

@book{dinwiddie_basic_2015,
	title = {Basic {Robotics}},
	isbn = {978-1-305-53705-7},
	abstract = {With no previous experience required, BASIC ROBOTICS walks readers step by step through the fundamentals of the industrial robot system. It begins with an exploration of the fascinating technological history that led to the modern robot, starting with events from Before the Common Era and ending with a glimpse of what the robots of tomorrow might become. From there the book explores safety, various parts of the robot, tooling, power transmission systems, the basics off programming, troubleshooting, maintenance, and much more. Engaging photos highlight various robotic systems and their parts, while stories of real-world events bring text concepts to life. This innovative First Edition incorporates many of the initiatives of STEM and is the culmination of lessons learned from the author's years of teaching robotics in various formats--from the traditional classroom to the industrial production floor with systems ranging from the LEGO Mindstorms NXT to the FANUC robot.Important Notice: Media content referenced within the product description or the product text may not be available in the ebook version.},
	language = {en},
	publisher = {Cengage Learning},
	author = {Dinwiddie, Keith},
	month = jan,
	year = {2015},
	keywords = {Technology \& Engineering / Mechanical},
	pages = {77}
}

@misc{jogging_2017,
	title = {Jogging the {Robot}},
	url = {https://motioncontrolsrobotics.com/jogging-the-robot/},
	abstract = {Jogging the robot - In this Tech Talk How to Robot Series article we are going to go through the steps to take when you are jogging the robot.},
	language = {en-US},
	urldate = {2020-06-04},
	journal = {Motion Controls Robotics - Certified FANUC System Integrator},
	month = nov,
	year = {2017},
	note = {Library Catalog: motioncontrolsrobotics.com}
}

@misc{echtzeitsystem_2020,
	title = {Echtzeitsystem},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://de.wikipedia.org/w/index.php?title=Echtzeitsystem&oldid=200650574},
	abstract = {Als Echtzeitsysteme (englisch real-time systems) werden „Systeme zur unmittelbaren Steuerung und Abwicklung von Prozessen“ bezeichnet, die dafür an sie gestellte quantitative Echtzeitanforderungen erfüllen müssen. Diese kommen in diversen Technikgebieten zur Anwendung, etwa in der Prozessleittechnik, in Motorsteuerungen, in der Satellitensystemtechnik, in Signal- und Weichenstellanlagen, in der Robotik und in weiteren Bereichen.
Oft besteht die Anforderung darin, dass ein Ergebnis innerhalb eines vorher fest definierten Zeitintervalls garantiert berechnet ist, also vor einer bestimmten Zeitschranke vorliegt. Die Größe des Zeitintervalls spielt dabei keine Rolle: Während bei einigen Aufgaben (z. B. in der Motorsteuerung) eine Sekunde bereits zu lang sein kann, reichen für andere Probleme Stunden oder sogar Tage. Ein Echtzeitsystem muss also nicht nur ein Mess- oder Berechnungsergebnis mit dem richtigen Wert, sondern dasselbe auch noch rechtzeitig liefern. Andernfalls hat das System versagt.
In der Praxis lässt sich eine beliebig kleine Zeitschranke mangels genügend schneller Hardware nicht immer realisieren. Daher spricht man auch von „in Echtzeit“, wenn Programme ohne spürbare Verzögerung arbeiten. Diese Definition ist jedoch sehr unsauber. Grundsätzlich falsch ist es, „Echtzeitsystem“ als Synonym für „besonders schnell“ anzusehen. Im Gegenteil, Echtzeitsysteme müssen entsprechende Leerläufe einplanen, um auch in besonders fordernden Situationen ihren Echtzeitanforderungen gerecht zu werden.},
	language = {de},
	urldate = {2020-06-05},
	journal = {Wikipedia},
	month = jun,
	year = {2020},
	note = {Page Version ID: 200650574}
}

@book{worn_echtzeitsysteme_2006,
	title = {Echtzeitsysteme: {Grundlagen}, {Funktionsweisen}, {Anwendungen}},
	isbn = {978-3-540-27416-2},
	shorttitle = {Echtzeitsysteme},
	abstract = {Das vorliegende Werk vermittelt ein solides Fundament zum Verständnis der wesentlichen Prinzipien, Funktionsweisen und Architekturen von Echtzeitsystemen. Dabei werden zunächst die Grundlagen der Automation von technischen Prozessen mithilfe der Steuerungs- und Regelungstechnik behandelt. Anschließend werden elementare Hardware- und Software-Architekturen sowie Kommunikationsmechanismen für Echtzeitsysteme beschrieben und Methoden der Echtzeitprogrammierung, der Echtzeitbetriebssysteme sowie der Echtzeit-Middleware fundiert dargestellt. Abgeschlossen wird das Buch durch Anwendungsbeispiele von Echtzeitsystemen aus der Fabrikautomation, wie z. B. speicherprogrammierbare Steuerungen oder Roboter- und Werkzeugmaschinensteuerungen. Dieses Lehrbuch richtet sich an Studierende der Informatik, Elektrotechnik, Regelungstechnik und des Maschinenbaus im fortgeschrittenen Grundstudium und ist in gleicher Weise für in der Praxis stehende Entwickler in diesen Fachgebieten geeignet.},
	language = {de},
	publisher = {Springer-Verlag},
	author = {Wörn, Heinz},
	month = may,
	year = {2006},
	keywords = {Computers / Computer Science, Computers / Expert Systems, Computers / Information Technology, Computers / Networking / General, Computers / Networking / Hardware, Computers / Software Development \& Engineering / Systems Analysis \& Design, Technology \& Engineering / Electrical}
}

@misc{garbage_collector_2020,
	title = {Garbage {Collection}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://de.wikipedia.org/w/index.php?title=Garbage_Collection&oldid=200472744},
	abstract = {Die Garbage Collection, kurz GC (englisch für Müllabfuhr, auch automatische Speicherbereinigung oder Freispeichersammlung genannt) bezeichnet in der Software- und Informationstechnik eine automatische Speicherverwaltung, die zur Vermeidung von Speicherproblemen beiträgt; der Vorteil wird mit einem erhöhten Ressourcenverbrauch erkauft. Unter anderem wird der Speicherbedarf eines Computerprogramms minimiert. Dabei wird zur Laufzeit versucht, nicht länger benötigte Speicherbereiche automatisch zu identifizieren, um diese dann freizugeben. Manche automatische Speicherbereinigungen führen darüber hinaus die noch verwendeten Speicherbereiche zusammen (Defragmentierung).},
	language = {de},
	urldate = {2020-06-06},
	journal = {Wikipedia},
	month = may,
	year = {2020},
	note = {Page Version ID: 200472744}
}

@misc{what_is_an_rtos_nodate,
	title = {What is an {RTOS} - {Real} {Time} {Operating} {System} {Information} and {Training}},
	url = {https://www.highintegritysystems.com/rtos/what-is-an-rtos/},
	abstract = {A Real Time Operating System, commonly known as an RTOS, is a software component that rapidly switches between tasks.},
	language = {en},
	urldate = {2020-06-06},
	journal = {High Integrity Systems},
	note = {Library Catalog: www.highintegritysystems.com}
}

@misc{xnu_2019,
	title = {{XNU}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://de.wikipedia.org/w/index.php?title=XNU&oldid=195027335},
	abstract = {XNU ist ein Kernel, der in dem freien Basisbetriebssystem (core operating system) Darwin verwendet wird. Darwin bildet die Grundlage von Apples Betriebssystem-Varianten macOS, iOS, iPadOS, tvOS und watchOS. XNU wird als freie Software unter Version 2 der Apple Public Source License (APSL) veröffentlicht. Seinen Ursprung hat der Kernel u. a. im Betriebssystem NeXTStep.},
	language = {de},
	urldate = {2020-06-06},
	journal = {Wikipedia},
	month = dec,
	year = {2019},
	note = {Page Version ID: 195027335}
}

@misc{sched_deadline_2020,
	title = {{SCHED}\_DEADLINE},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=SCHED_DEADLINE&oldid=951203928},
	abstract = {SCHED\_DEADLINE is a CPU scheduler available in the Linux kernel since version 3.14, based on the Earliest Deadline First (EDF) and Constant Bandwidth Server (CBS) algorithms, supporting resource reservations: each task scheduled under such policy is associated with a budget Q (aka runtime), and a period P, corresponding to a declaration to the kernel that Q time units are required by that task every P time units, on any processor. This makes SCHED\_DEADLINE particularly suitable for real-time applications, like multimedia or industrial control, where P corresponds to the minimum time elapsing between subsequent activations of the task, and Q corresponds to the worst-case execution time needed by each activation of the task.},
	language = {en},
	urldate = {2020-06-06},
	journal = {Wikipedia},
	month = apr,
	year = {2020},
	note = {Page Version ID: 951203928}
}

@misc{leemhuis_linux_nodate,
	title = {Linux 5.3 freigegeben: {Prioritäten} deckeln und {Trouble} für {Nvidia}},
	shorttitle = {Linux 5.3 freigegeben},
	url = {https://www.heise.de/ct/artikel/Linux-5-3-freigegeben-Prioritaeten-deckeln-und-Trouble-fuer-Nvidia-4470638.html},
	abstract = {Der neue Kernel schaufelt 16 Millionen weitere IPv4-Adressen frei, indem er ein Relikt ad acta legt. Den ISDN-Support stutzen die Entwickler zusammen. Zum Ausgleich bekommt Linux eine Funktion für Zeitreisen.},
	language = {de},
	urldate = {2020-06-06},
	journal = {c't Magazin},
	author = {Leemhuis, Thorsten},
	note = {Library Catalog: www.heise.de}
}

@misc{microsoft_windows_ce_2019,
	title = {Microsoft {Windows} {CE}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://de.wikipedia.org/w/index.php?title=Microsoft_Windows_CE&oldid=194448187},
	abstract = {Windows CE ist eine Betriebssystemlinie von Microsoft und für eingebettete Systeme, Thin Clients und Handhelds vorgesehen. Das Betriebssystem basiert auf keiner anderen Windows-Version und ist keine „verkleinerte Version“.
Die grafische Benutzeroberfläche kann, je nach Zusammenstellung des Herstellers, einer von Windows NT gleichen oder an kleine Bildschirme sowie den Einsatzzweck angepasst sein. Eine Win32-API ist auf beiden Plattformen vorhanden, so dass es theoretisch möglich wäre, Quelltext für beide zugleich zu entwickeln. In der Realität funktioniert dies aber meist nicht so einfach: Obwohl Windows CE eine Win32-basierte Programmierschnittstelle (englisch application programming interface, API) enthält, gibt es tiefgreifende Unterschiede, die die Portierungen von x86-Windows-Software in der Realität meist sehr aufwändig macht.
Nk.exe ist der Kernel von Windows CE, der völlig unabhängig von Windows NT von Grund auf neu entwickelt wurde. Windows CE basiert nicht auf einer der anderen Windows-Varianten (9x- oder NT-basiert) und ist keine „verkleinerte Version“ davon. Zwischenzeitlich unterstützte das Betriebssystem rund ein Dutzend Prozessorarchitekturen.
Im Unterschied zu DOS- oder NT-basierten Windows-Systemen wurde Windows CE in Hinblick auf Echtzeitfähigkeit entwickelt. Die Echtzeiteigenschaften hängen jedoch von einer Vielzahl von Faktoren ab, die dazu führen, dass die Echtzeitfähigkeit in der Praxis nicht zweifelsfrei vorhanden ist. Zu diesen Faktoren gehören die Eigenschaften der Zielarchitektur, Unterstützung durch Hardware und Treiber sowie vor allem die Schwierigkeit der Verifizierbarkeit von Echtzeitfähigkeit. Echtzeitfähigkeit ist nur für eine sehr stark begrenzte Zahl von Plattformen unter bestimmten Voraussetzungen teilweise anhand heuristischer Methoden überprüft worden, so dass es nicht möglich ist, von allgemeiner Echtzeitfähigkeit im Zusammenhang mit Windows CE zu sprechen.
Die Buchstaben „CE“ sind keine Abkürzung, sondern Andeutung einer Vielzahl von Konstruktionsgrundsätzen wie Kompaktheit, Kompatibilität (englisch compatibility) und Effizienz (englisch efficiency). Mit Version 6.0 erweiterte Microsoft den Namen zu Windows Embedded CE und mit Version 7 wurde das System zu Windows Embedded Compact umbenannt, damit es sich einheitlich in die Produktlinie Windows Embedded der Betriebssysteme von Microsoft für eingebettete Systeme einfügt.Eine weitere CE Umbenennung wurde ab 2002 als Microsoft Windows Mobile vermarktet. 2010 wurde eine CE-Variante mit spezieller Benutzer-Oberfläche Windows Phone 7 genannt.},
	language = {de},
	urldate = {2020-06-06},
	journal = {Wikipedia},
	month = nov,
	year = {2019},
	note = {Page Version ID: 194448187}
}

@book{chattopadhyay_embedded_2013,
	title = {{EMBEDDED} {SYSTEM} {DESIGN}},
	isbn = {978-81-203-4730-4},
	abstract = {Embedded system, as a subject, is an amalgamation of different domains, such as digital design, architecture, operating systems, interfaces, and algorithmic optimization techniques. This book acquaints the students with the alternatives and intricacies of embedded system design. It is designed as a textbook for the undergraduate students of Electronics and Communication Engineering, Electronics and Instrumentation Engineering, Computer Science and Engineering, Information Communication Technology (ICT), as well as for the postgraduate students of Computer Applications (MCA). While in the hardware platform the book explains the role of microcontrollers and introduces one of the most widely used embedded processor, ARM, it also deliberates on other alternatives, such as digital signal processors, field programmable devices, and integrated circuits. It provides a very good overview of the interfacing standards covering RS232C, RS422, RS485, USB, IrDA, Bluetooth, and CAN. In the software domain, the book introduces the features of real-time operating systems for use in embedded applications. Various scheduling algorithms have been discussed with their merits and demerits. The existing real-time operating systems have been surveyed. Guided by cost and performance requirements, embedded applications are often implemented partly in hardware and partly in software. The book covers the different optimization techniques proposed in the literature to take a judicious decision about this partitioning of application tasks. Power-aware design of embedded systems has also been dealt with. In its second edition, the text has been extensively revised and updated. Almost all the chapters have been modified and elaborated including detailed discussion on hardware platforms—ARM, DSP, and FPGA. The chapter on “interfacing standards” has been updated to incorporate the latest information. The new edition will be thereby immensely useful to the students, practitioners and advanced readers. Key Features • Presents a considerably wide coverage of the field of embedded systems • Discusses the ARM microcontroller in detail • Provides numerous exercises to assess the learning process • Offers a good discussion on hardware–software codesign},
	language = {en},
	publisher = {PHI Learning Pvt. Ltd.},
	author = {CHATTOPADHYAY, SANTANU},
	month = apr,
	year = {2013},
	keywords = {Computers / Microprocessors},
	pages = {106--107}
}

@article{hall_windows_ce_2005,
	title = {Windows {CE} 5.0 for real-time systems},
	language = {en},
	author = {Hall, Mike},
	year = {2005}
}

@article{marchesin_using_2004,
	title = {Using {Linux} for real-time applications},
	volume = {21},
	issn = {1937-4194},
	doi = {10.1109/MS.2004.1331295},
	abstract = {We've selected a topic for practitioners in the embedded and real-time domains, namely how to use Linux for real-time applications. The article is hands-on: it not only summarizes selection criteria and introduction schemes for RTLinux but also shows how Linux was actually integrated in an existing (legacy) architecture. For small and medium-sized businesses to stay competitive, they need communication systems that offer not only excellent telephone service but also Internet and data-handling capability. As a solution to this problem, we have built a comprehensive communication appliance called OmniPCX Office, or OXO - a preconfigured server integrating data, Internet, and voice communication capabilities. Rather than using proprietary software to support the OXO platform, we chose Linux with an RTLinux extension. This column explains why we chose it and how OXO uses it, focusing particularly on architecture and realtime aspects.},
	number = {5},
	journal = {IEEE Software},
	author = {Marchesin, A.},
	month = sep,
	year = {2004},
	note = {Conference Name: IEEE Software},
	keywords = {Access protocols, Computer architecture, data-handling capability, Delay, Guidelines, Internet, ISDN, Kernel, Linux, OmniPCX Office, Open source software, OXO platform, public domain software, Real time systems, real-time, real-time application, real-time systems, RTLinux, software architecture, voice communication},
	pages = {20}
}

@inproceedings{behnisch_iso_2008,
	title = {{ISO} 10218 – von der neuen {Norm} zur {Anwendung} / {ISO} 10218 – {Putting} the {New} {Standard} into {Practice}},
	abstract = {Kurzfassung
Seit 2006 ist der erste Teil der neuen Sicherheitsnorm ISO 10218-1 veröffentlicht. Der Teil 2 „Robotersystem und Integration“ wird im Jahr 2008 fertig gestellt werden und soll ein Handbuch für die Anwender und Integratoren von Robotersystemen darstellen. Neben der Darstellung aktueller und zukünftiger Robotertechnologien soll vor allem der Anwender einen tiefen Einblick erhalten, was ihn mit dem Teil 2 der Roboternorm erwartet. Zwar ist der ISO –Standard international akzeptiert, so wurde vor kurzem die ISO 10218-1 von der ANSI-RIA angenommen, doch welche Hürden auf dem globalen Markt genommen werden müssen, stellt gerade die Maschinenhersteller, die Roboter in ihren Anlagen vorsehen, vor erhebliche Probleme. Von der Planung bis zur Abnahme soll dieser Vortrag einen klaren Weg aufzeigen, den Integratoren zu begehen haben, um letztlich allen Sicherheitsanforderungen gerecht zu werden. Dazu wird auch über den Tellerrand geschaut und gerade die Anforderungen aus dem nordamerikanischen und asiatischen Raum aufgezeigt.

Von großem Interesse ist besonders, wie man nun diese neuen Sicherheitstechnologien effizient und richtig einsetzen kann. Neue Entwicklungen bei den Roboterherstellern als auch neue sicherheitsgerichtete Überwachungen, wie z.B. sichere Kameras, ergeben eine Vielzahl von Möglichkeiten, die sich jedoch auch in ihren Kosten sehr stark von einander unterscheiden können. Dabei sollen mögliche Einsparpotentiale aufgezeigt werden, ohne jedoch die notwendigen Sicherheitsanforderungen zu vernachlässigen.

Dieser Vortrag wird weitestgehend produktneutral gehalten. Es wird keine Herausstellung der Merkmale eines Roboterherstellers oder Sicherheitstechniklieferanten erfolgen. Der Fokus gilt dem Anwender und den Anforderungen, die für die Umsetzung der Applikation sicherheitsgerecht und konform zur Norm zu bewältigen sind.

Abstract
The first part of the new industrial robot safety standard ISO 10218-1; “Robots for Industrial Environments - Safety Requirements; Part 1: Robot,” was published in 2006. Part 2 of the standard, subtitled “Robot System and Integration,” will be completed in 2008 and is intended to be a handbook for users, application engineers and integrators of robot systems. In addition to describing current and future robot technologies, this contribution will provide an in-depth view of what part 2 of the standard will offer to the user. While the ISO standard is internationally accepted, noting for example that the ANSI-RIA has recently adopted it, the obstacles to be overcome in the global market constitute an appreciable challenge to machine suppliers that include robots in their systems. From the planning phase all the way to acceptance testing, this paper points out a clear path for integrators to follow so as to satisfy all safety requirements. In addition, we survey requirements typical for North American and Asian installations.

Of particular interest is how new safety technologies can be used properly and efficiently in actual installations. Current developments both from suppliers of industrial robots and from suppliers of safety monitoring equipment, such as safe camera systems, enable a host of new possibilities, which can vary strongly in cost. We point out cost savings potential without compromising safety requirements.

This contribution is unbiased – there will be no focus on specific features of the product offerings of any robot or safety equipment suppliers. Our attention is centered on the user and on the requirements that he needs to master for the safety-compliant realization of his application.},
	author = {Behnisch, Kevin and Matthias, Bjoern},
	month = jun,
	year = {2008},
	pages = {2--14}
}

@book{koubaa_robot_operating_system_2019,
	series = {Studies in {Computational} {Intelligence}},
	title = {Robot {Operating} {System} ({ROS}): {The} {Complete} {Reference} ({Volume} 3)},
	isbn = {978-3-319-91589-0},
	shorttitle = {Robot {Operating} {System} ({ROS})},
	abstract = {Building on the successful first and second volumes, this book is the third volume of the Springer book on the Robot Operating System (ROS): The Complete Reference. The Robot Operating System is evolving from year to year with a wealth of new contributed packages and enhanced capabilities. Further, the ROS is being integrated into various robots and systems and is becoming an embedded technology in emerging robotics platforms. The objective of this third volume is to provide readers with additional and comprehensive coverage of the ROS and an overview of the latest achievements, trends and packages developed with and for it. Combining tutorials, case studies, and research papers, the book consists of sixteen chapters and is divided into five parts. Part 1 presents multi-robot systems with the ROS. In Part 2, four chapters deal with the development of unmanned aerial systems and their applications. In turn, Part 3 highlights recent work related to navigation, motion planning and control. Part 4 discusses recently contributed ROS packages for security, ROS2, GPU usage, and real-time processing. Lastly, Part 5 deals with new interfaces allowing users to interact with robots. Taken together, the three volumes of this book offer a valuable reference guide for ROS users, researchers, learners and developers alike. Its breadth of coverage makes it a unique resource.},
	language = {en},
	urldate = {2020-06-07},
	publisher = {Springer International Publishing},
	editor = {Koubaa, Anis},
	year = {2019},
	doi = {10.1007/978-3-319-91590-6}
}

@misc{ros_distributions_nodate,
	title = {Distributions - {ROS} {Wiki}},
	url = {http://wiki.ros.org/Distributions},
	urldate = {2020-06-07}
}

@misc{robot_operating_system_2020,
	title = {Robot {Operating} {System}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://de.wikipedia.org/w/index.php?title=Robot_Operating_System&oldid=200591087},
	abstract = {Robot Operating System (ROS) ist ein Framework für persönliche Roboter. Die Entwicklung begann 2007 am Stanford Artificial Intelligence Laboratory im Rahmen des Stanford-AI-Robot-Projektes (STAIR) und wurde ab 2009 hauptsächlich am Robotikinstitut Willow Garage weiterentwickelt. Seit April 2012 wird ROS von der neu gegründeten, gemeinnützigen Organisation Open Source Robotics Foundation (OSRF) unterstützt und seit Beendigung der operativen Tätigkeit von Willow Garage 2013 von dieser koordiniert, gepflegt und weiterentwickelt. Seit 2013 beschäftigt sich das ROS Industrial Consortium mit der Förderung und Unterstützung von ROS für Anwendungen in der Industrierobotik. In Europa koordiniert das Fraunhofer IPA die Aktivitäten des ROS Industrial Consortium Europe.},
	language = {de},
	urldate = {2020-06-07},
	journal = {Wikipedia},
	month = jun,
	year = {2020},
	note = {Page Version ID: 200591087}
}

@article{pohl_robot_operating_system_2014,
	title = {Robot {Operating} {System} ({ROS}): {Safe} \& {Insecure}},
	shorttitle = {Robot {Operating} {System} ({ROS})},
	abstract = {„Unsichere Software ist die Achillesferse der Industrie 4.0", warnt der Sicherheits-Experte Prof. Dr. Hartmut Pohl. Im Vorfeld der Automatica hat er exklusiv für die Automationspraxis das in der Servicerobotik beliebte Opensource-Roboterbetriebssystem ROS einer Sicherheitsprüfung unterzogen. Sein Fazit: „ROS als relativ junges System berücksichtigt weder beim Design noch bei der Implementierung Aspekte der Security. Auf der Basis von ROS entwickelte Systeme sind daher völlig unsicher.},
	journal = {Automationspraxis},
	author = {Pohl, Hartmut},
	month = may,
	year = {2014},
	pages = {5--7}
}

@misc{rosorg_is_ros_for_me_nodate,
	title = {{ROS}.org {\textbar} {Is} {ROS} {For} {Me}?},
	url = {https://www.ros.org/is-ros-for-me/},
	language = {en-US},
	urldate = {2020-06-07},
	note = {Library Catalog: www.ros.org}
}

@misc{ros_2_features_nodate,
	title = {Features {Status}},
	url = {https://index.ros.org/doc/ros2/Features/#features},
	urldate = {2020-06-07}
}

@misc{roboter_schnittstellen_nodate,
	title = {Roboter schneller programmieren},
	url = {https://www.industr.com/de/schnellere-entwicklung-anwendungen-robot-operating-system-ros-1712541},
	abstract = {Robotersysteme sind dank neuer Technologien auf dem Vormarsch. Sie einzurichten ist jedoch zeit- und kostenintensiv und nur für hohe Stückzahlen rentabel.},
	language = {de},
	urldate = {2020-06-07},
	journal = {https://www.industr.com},
	note = {Library Catalog: www.industr.com}
}

@misc{ros-master-node-topicpng_nodate,
	title = {{ROS}-master-node-topic.png ({PNG}-{Grafik}, 1725 × 769 {Pixel})},
	url = {https://upload.wikimedia.org/wikipedia/commons/e/e7/ROS-master-node-topic.png},
	urldate = {2020-06-07}
}

@misc{rosconcepts_nodate,
	title = {de/{ROS}/{Concepts} - {ROS} {Wiki}},
	url = {http://wiki.ros.org/de/ROS/Concepts},
	urldate = {2020-06-07}
}

@misc{tof-kamera_2019,
	title = {{TOF}-{Kamera}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://de.wikipedia.org/w/index.php?title=TOF-Kamera&oldid=189220682},
	abstract = {TOF-Kameras sind 3D-Kamerasysteme, die mit dem Laufzeitverfahren (englisch: time of flight, TOF, auch ToF) Distanzen messen. Sie werden nach dem verwendeten PMD-Sensor auch PMD-Kameras genannt. Dazu wird die Szene mittels eines Lichtpulses ausgeleuchtet, und die Kamera misst für jeden Bildpunkt die Zeit, die das Licht bis zum Objekt und wieder zurück braucht. Die benötigte Zeit ist direkt proportional zur Distanz. Die Kamera liefert somit für jeden Bildpunkt die Entfernung des darauf abgebildeten Objektes. Das Prinzip entspricht dem Laserscanning mit dem Vorteil, dass eine ganze Szene auf einmal aufgenommen wird und nicht abgetastet werden muss.
TOF-Kameras sind im Gegensatz zu anderen Methoden eine relativ neue Entwicklung. Die Systeme können im Entfernungsbereich von einigen Dezimetern bis ca. 40 m eingesetzt werden. Die Distanzauflösung beträgt dabei etwa 1 cm, die lateralen Auflösungen erreichen etwa 200 × 200 Pixel. Ein Vorteil dieser Kameras ist die hohe Bildwiederholrate von bis zu 512 Bildern pro Sekunde.
Beispiele für TOF-Kameras},
	language = {de},
	urldate = {2020-06-08},
	journal = {Wikipedia},
	month = jun,
	year = {2019},
	note = {Page Version ID: 189220682}
}

@misc{understanding_infrared_sensors_nodate,
	title = {Understanding {Active} \& {Passive} {Infrared} {Sensors} ({PIR}) and {Their} {Uses}},
	url = {https://www.arrow.com/en/research-and-events/articles/understanding-active-and-passive-infrared-sensors},
	abstract = {Infrared sensors are more common than most people realize. Learn about the differences between active and passive infrared sensors and their applications.},
	language = {en},
	urldate = {2020-06-08},
	journal = {Arrow.com},
	note = {Library Catalog: www.arrow.com}
}

@misc{azure_kinect_2020,
	title = {Azure {Kinect}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Azure_Kinect&oldid=945489630},
	abstract = {The Azure Kinect DK is a developer kit and PC peripheral which employs the use of artificial intelligence (AI) sensors for computer vision and speech models. It is the successor to the Microsoft Kinect line of sensors, and is now connected to the Microsoft Azure cloud. It is based on the depth sensor presented during 2018 ISSCC.The Azure Kinect retails for \$399.00 in the US and China. Based on a recent announcement, devices will also start shipping to the UK, Germany, and Japan in March 2020. The kit includes a 12 megapixel RGB camera supplemented by 1 megapixel-depth camera for body tracking. It also has a 360-degree seven-microphone array and an orientation sensor.While the previous iteration of Microsoft's Kinect is primarily focused on gaming, the device is aimed at broad-based enterprise users and is also targeted towards other markets such as logistics, robotics, health care, and retail. With the kit, developers are expected to develop corporate applications connected to Microsoft's cloud and AI technologies. The Azure Kinect is also used in volumetric capture workflows through the use of software tools such as Depthkit or EF EVE which allows the highest number of Azure Kinects to be connected into one consumer friendly volumetric capture rig. These software allow users to create interactive virtual reality experiences with human performances.},
	language = {en},
	urldate = {2020-06-08},
	journal = {Wikipedia},
	month = mar,
	year = {2020},
	note = {Page Version ID: 945489630}
}

@misc{azure_kinect_dk_nodate,
	title = {Azure {Kinect} {DK} – {Develop} {AI} {Models} {\textbar} {Microsoft} {Azure}},
	url = {https://azure.microsoft.com/en-us/services/kinect-dk/},
	abstract = {Developers: Build advanced computer vision and speech models with a 1-MP depth sensor,
12-MP RGB camera, and 7-mic audio array in a single device.},
	language = {en},
	urldate = {2020-06-08},
	note = {Library Catalog: azure.microsoft.com}
}

@misc{tesych_azure_nodate,
	title = {Azure {Kinect} {DK} hardware specifications},
	url = {https://docs.microsoft.com/en-us/azure/kinect-dk/hardware-specification},
	abstract = {Understand the components, specifications, and capabilities of the Azure Kinect DK.},
	language = {en-us},
	urldate = {2020-06-08},
	author = {tesych},
	note = {Library Catalog: docs.microsoft.com}
}

@misc{widowx_200_nodate,
	title = {{WidowX} 200 {Robot} {Arm} - {X}-{Series} {Robotic} {Arm}},
	url = {https://www.trossenrobotics.com/widowx-200-robot-arm.aspx},
	urldate = {2020-06-11}
}

@misc{qm13_azure_joints_nodate,
	title = {Azure {Kinect} body tracking joints},
	url = {https://docs.microsoft.com/en-us/azure/kinect-dk/body-joints},
	abstract = {Understand the body frame, joints, joint coordinates, and joint hierarchy in the Azure Kinect DK.},
	language = {en-us},
	urldate = {2020-06-11},
	author = {qm13},
	note = {Library Catalog: docs.microsoft.com}
}

@misc{microsoftazure-kinect-sensor-sdk_2020,
	title = {microsoft/{Azure}-{Kinect}-{Sensor}-{SDK}},
	copyright = {MIT},
	url = {https://github.com/microsoft/Azure-Kinect-Sensor-SDK},
	abstract = {A cross platform (Linux and Windows) user mode SDK to read data from your Azure Kinect device.},
	urldate = {2020-06-11},
	publisher = {Microsoft},
	month = jun,
	year = {2020},
	note = {original-date: 2018-12-10T17:50:05Z},
	keywords = {kinect, sdk}
}

@misc{qm13_azure_kinect_release_notes_nodate,
	title = {Azure {Kinect} {Body} {Tracking} {SDK} download},
	url = {https://docs.microsoft.com/en-us/azure/kinect-dk/body-sdk-download},
	abstract = {Understand how to download each version of the Azure Kinect Sensor SDK on Windows or Linux.},
	language = {en-us},
	urldate = {2020-06-11},
	author = {qm13},
	note = {Library Catalog: docs.microsoft.com}
}

@book{osterrieder_komponentenmodelle_2004,
	title = {Komponentenmodelle für {Web}-{Anwendungen}},
	isbn = {978-3-8324-8119-3},
	abstract = {Inhaltsangabe:Zusammenfassung: Die Diplomarbeit vergleicht die de-facto-Standards der komponentenbasierten Softwareentwicklung und die Spezifikationen und Frameworks zur Entwicklung von Web-Anwendungen, die mit den untersuchten Komponentenmodellen in Verbindung stehen. Um die Ziele dieser Diplomarbeit zu erreichen, wurden im Kapitel 2 die Grundlagen der komponentenbasierten Softwareentwicklung vorgestellt. Anschließend wurde ein Überblick über die Komponentenmodelle und Spezifikationen der de-facto-Standards CORBA, der Enterprise JavaBeans, des .NET Frameworks und der Web-Services gegeben. Das Kapitel 2 schließt mit einem Vergleich der vorgestellten Komponentenmodelle, welcher durch eine tabellarische Übersicht verdeutlicht wurde. Kapitel 3 beschäftigt sich in erster Linie mit Grundlagen und Architekturen von Web-Anwendungen. Dabei wurden die wichtigsten Anforderungen an Web-Anwendungen beschrieben, welche als typische Eigenschaften von Web-Anwendungen gesehen werden können. Diese Anforderungen wurden in einem Kriterienkatalog zusammengefasst. Er gilt als Verlgleichsgrundlage der beschriebenen Techniken. Ein Überblick über die Architekturen von Web-Anwendungen schafft einen Einblick in mehrschichtige Architekturen und deren Middleware. Ein oft verwendetes Entwurfsmuster für Architekturen von Web-Anwendungen ist das Model-View-Controller-Muster, welches abschließend in Kapitel 3 beschrieben wurde. In Kapitel 4 wurden die Spezifikationen und Frameworks der beschriebenen Komponentenmodelle, im Zusammenhang mit Web-Anwendungen, näher untersucht. Die Untersuchungen beziehen sich auf die Architekturen der jeweiligen Spezifikationen und Frameworks und deren Lösungsstrategien um den in Kapitel 3 gefundenen Anforderungen aus dem Kriterienkatalog gerecht zu werden. Praktisches Ziel der Diplomarbeit war die Entwicklung einer komponentenbasierten Web-Anwendung in Form eines Terminkalenders. Die dazu notwendigen Aktionen sind in Kapitel 5 zusammengefasst. Dazu wurde zuerst die zu entwickelnde Web-Anwendung spezifiziert, indem funktionale und nicht-funktionale Anforderungen an die Anwendung erhoben wurden. Anschließend erfolgte eine Auseinandersetzung mit den Vor- und Nachteilen der vorgestellten Techniken von CORBA, der J2EE Spezifikation, dem .NET Framework und er Web-Services um ein geeignetes Komponentenmodell für den Terminkalender zu finden. Die Entscheidung fiel auf die J2EE Spezifikation und Web-Services. Die restlichen Abschnitte beschreiben [...]},
	language = {de},
	publisher = {diplom.de},
	author = {Osterrieder, Christian},
	month = jul,
	year = {2004},
	keywords = {Computers / Internet / General},
	pages = {80--86}
}

@book{kircher_it_2006,
	title = {{IT}: {Technologien}, {Lösungen}, {Innovationen}},
	isbn = {978-3-540-46164-7},
	shorttitle = {{IT}},
	abstract = {IT ist das Zauberwort unserer Zeit. Viele Fragen, die sich für Unternehmen in der globalisierten Welt stellen, finden ihre Lösungen im optimierten Einsatz von IT-Technologien. Ohne IT ist es nicht mehr möglich, die für die Überlebensfähigkeit eines Unternehmens und dessen Erfolg notwendigen Innovationen zu erreichen. Führende Experten aus einem der renommiertesten europäischen Entwicklungszentren gehen auf die wichtigsten technologischen Entwicklungen ein und erläutern deren Umsetzung für Unternehmen im Wettbewerb. Besondere Betonung liegt dabei auf dem Aspekt der IT als Innovationsmotor. Das Buch gibt gleichzeitig einen fundierten Überblick über die wichtigsten IT-Technologien, die heute und in naher Zukunft in zum Einsatz kommen.},
	language = {de},
	publisher = {Springer Science \& Business Media},
	author = {Kircher, Herbert},
	month = nov,
	year = {2006},
	keywords = {Computers / Information Technology, Computers / System Administration / Storage \& Retrieval, Business \& Economics / General, Business \& Economics / Management, Business \& Economics / Production \& Operations Management, Business \& Economics / Purchasing \& Buying},
	pages = {8--15}
}

@article{brauer_gestenerkennung_nodate,
	title = {Gestenerkennung mit einem {Datenhandschuh}},
	language = {de},
	author = {Brauer, Volker}
}

@misc{lxc_2020,
	title = {{LXC}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://de.wikipedia.org/w/index.php?title=LXC&oldid=199359030},
	abstract = {LXC (Linux Containers) ist ein Verfahren zur Virtualisierung auf Betriebssystemebene, das mehrere voneinander isoliert laufende Linux-Systeme auf einem einzigen Host ermöglicht.},
	language = {de},
	urldate = {2020-06-14},
	journal = {Wikipedia},
	month = apr,
	year = {2020},
	note = {Page Version ID: 199359030}
}

@misc{lxc_2017,
	title = {{LXC} und {LXD}: was sind {Linux} {Container}? - {Cloud} \& {Hosting}},
	shorttitle = {{LXC} und {LXD}},
	url = {https://www.webhod.de/lxc-und-lxd-was-sind-linux-container/},
	abstract = {LXC, LXC, Docker oder doch CoreOS? Wo liegen hier die Unterschiede? Wir haben einige Informationen zu Linux Container für Sie zusammengestellt.},
	language = {de-DE},
	urldate = {2020-06-14},
	journal = {Hosted Exchange, Office 365 und hybrid Office 365},
	month = dec,
	year = {2017},
	note = {Library Catalog: www.webhod.de
Section: Cloud \& Hosting}
}

@misc{gazebo_nodate,
	title = {Gazebo},
	url = {http://gazebosim.org/},
	urldate = {2020-06-15}
}

@misc{vrep_vs_gazebo_nodate,
	title = {V-{REP}, {Gazebo} or {ARGoS}? {A} robot simulators comparison :: {LENKASPACE} ::},
	shorttitle = {V-{REP}, {Gazebo} or {ARGoS}?},
	url = {http://lenkaspace.net/tutorials/programming/robotSimulatorsComparison},
	abstract = {Let’s have a look at three commonly used open-source simulators for robotics: V-REP, Gazebo and ARGoS, to find out which one suits your project the best.},
	urldate = {2020-06-15},
	journal = {LENKASPACE},
	note = {Library Catalog: lenkaspace.net}
}

@misc{moveit_nodate,
	title = {{MoveIt} {Motion} {Planning} {Framework}},
	url = {https://moveit.ros.org/},
	urldate = {2020-06-15}
}

@misc{moveit_tutorial_nodate,
	title = {{MoveIt} {Tutorials} — moveit\_tutorials {Melodic} documentation},
	url = {https://ros-planning.github.io/moveit_tutorials/},
	urldate = {2020-06-15}
}

@misc{tesych_about_azure_kinect_sdks_nodate,
	title = {About {Azure} {Kinect} {DK}},
	url = {https://docs.microsoft.com/en-us/azure/kinect-dk/about-azure-kinect-dk},
	abstract = {Overview of the Azure Kinect developer kit (DK) tools and integrated services.},
	language = {en-us},
	urldate = {2020-06-15},
	author = {tesych},
	note = {Library Catalog: docs.microsoft.com}
}

@misc{why_dont_we_use_ros_nodate,
	title = {Why don't we use {ROS}?},
	url = {https://www.pulurobotics.fi/blog/pulurobotics-blog-1/post/why-don-t-we-use-ros-7},
	language = {en-US},
	urldate = {2020-06-15},
	journal = {Pulurobotics Oy Ltd},
	note = {Library Catalog: www.pulurobotics.fi}
}

@misc{gestik_2020,
	title = {Gestik},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://de.wikipedia.org/w/index.php?title=Gestik&oldid=197084398},
	abstract = {Gestik ist die Gesamtheit der Gesten, die als Bewegungen der zwischenmenschlichen Kommunikation dienen. Insbesondere Bewegungen der Arme, Hände und des Kopfes begleiten oder ersetzen Mitteilungen in einer jeweiligen Lautsprache. Gesten sind Zeichen der nonverbalen Kommunikation.},
	language = {de},
	urldate = {2020-06-15},
	journal = {Wikipedia},
	month = feb,
	year = {2020},
	note = {Page Version ID: 197084398}
}

@misc{gesten_liste_2020,
	title = {Liste von {Gesten}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://de.wikipedia.org/w/index.php?title=Liste_von_Gesten&oldid=200588792},
	language = {de},
	urldate = {2020-06-15},
	journal = {Wikipedia},
	month = jun,
	year = {2020},
	note = {Page Version ID: 200588792}
}

@article{pavlovic_visual_1997,
	title = {Visual interpretation of hand gestures for human-computer interaction: a review},
	volume = {19},
	issn = {1939-3539},
	shorttitle = {Visual interpretation of hand gestures for human-computer interaction},
	doi = {10.1109/34.598226},
	abstract = {The use of hand gestures provides an attractive alternative to cumbersome interface devices for human-computer interaction (HCI). In particular, visual interpretation of hand gestures can help in achieving the ease and naturalness desired for HCI. This has motivated a very active research area concerned with computer vision-based analysis and interpretation of hand gestures. We survey the literature on visual interpretation of hand gestures in the context of its role in HCI. This discussion is organized on the basis of the method used for modeling, analyzing, and recognizing gestures. Important differences in the gesture interpretation approaches arise depending on whether a 3D model of the human hand or an image appearance model of the human hand is used. 3D hand models offer a way of more elaborate modeling of hand gestures but lead to computational hurdles that have not been overcome given the real-time requirements of HCI. Appearance-based models lead to computationally efficient "purposive" approaches that work well under constrained situations but seem to lack the generality desirable for HCI. We also discuss implemented gestural systems as well as other potential applications of vision-based gesture recognition. Although the current progress is encouraging, further theoretical as well as computational advances are needed before gestures can be widely used for HCI. We discuss directions of future research in gesture recognition, including its integration with other natural modes of human-computer interaction.},
	number = {7},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Pavlovic, V.I. and Sharma, R. and Huang, T.S.},
	month = jul,
	year = {1997},
	note = {Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {Communications technology, Computational modeling, computationally efficient purposive approaches, Computer displays, Computer vision, hand gestures, HCI, Human computer interaction, human-computer interaction, image recognition, Keyboards, Motion analysis, motion estimation, Potential well, real-time requirements, reviews, Tracking, user interfaces, Virtual reality, vision-based gesture recognition, visual interpretation}
}

@book{matschnig_korpersprache_2007,
	title = {Körpersprache},
	isbn = {978-3-8338-0789-3},
	abstract = {Es sind weniger die Themen zum Körpersprachen-Komplex, welche die Psychologin und Expertin für Selbstmarketing hier ausbreitet (die gehören zum Standardrepertoire des Genres), als die Präsentation der Inhalte. Ziel ist es, den Leser zu befähigen, sowohl die Gefühle, Gedanken und Beweggründe von Menschen aus deren Mimik, Gestik und Körperhaltung zu entschlüsseln, als auch sich selbst überzeugend durch seine nonverbalen Signale zu "vermarkten". Die Themenpalette reicht vom "1. Eindruck" über die Körpersprache im Privatbereich (Flirt, Partnerschaft) bis hin zur authentischen Positionierung im Job. Zur Präzisierung des Körpersprachen-Konzepts spielt die Autorin es anhand von 4 Persönlichkeitstypen (der Macher, der Herzliche, der Realist, der Visionär) durch. Was dabei besticht, sind die in großformatigen Farbfotos visualisierten Charakteristika der Körpersprache sowie - als Zusammenfassung an den Kapitelenden durch den "Lügendetektor"--Die wichtigsten verräterischen Gesten. Jetzt wünscht man sich das Ganze als DVD!},
	language = {de},
	publisher = {Gräfe Und Unzer},
	author = {Matschnig, Monika},
	month = sep,
	year = {2007},
	keywords = {Self-Help / Personal Growth / General}
}

@misc{matschnig_glossar_nodate,
	title = {Glossar {Körpersprache} und {Wirkung} - {Monika} {Matschnig}},
	url = {https://www.matschnig.com/medien-presse/glossar-koerpersprache/},
	abstract = {Von A wie Ablehnung bis bis Z wie Zuneigung! Das Glossar zur Körpersprache, Wirkung und Authentizität - von Keynote-Speaker und Trainer Monika Matschnig.},
	language = {de-DE},
	urldate = {2020-06-16},
	journal = {Körpersprache und Wirkungskompetenz für Führungskräfte, Manager, Politiker},
	note = {Library Catalog: www.matschnig.com}
}

@misc{handzeichen_gesten_2018,
	title = {Handzeichen – kennst du ihre {Bedeutung} wirklich?},
	url = {https://www.reden-ohne-worte.com/handzeichen-und-ihre-bedeutung/},
	abstract = {✪ Handzeichen – welche gibt es \& was sagen sie aus? ✔ Hände sind mit ​d​er ausdrückstärkste Teil unseres Körpers. ▶ Sie kommunizieren offen oder versteckt.},
	language = {de-DE},
	urldate = {2020-06-16},
	journal = {reden-ohne-worte.com},
	month = sep,
	year = {2018},
	note = {Library Catalog: www.reden-ohne-worte.com
Section: Gestik}
}

@misc{gesten_vergleich_nodate,
	title = {Gesten im {Ausland}: {Achtung} {Redner} und {Reisende}! - {Redenwelt}},
	url = {https://www.redenwelt.de/rede-tipps/gesten-im-ausland/},
	urldate = {2020-06-16}
}

@incollection{schleicher_einfuhrung_2020,
	address = {Wiesbaden},
	series = {Gestaltung hybrider {Mensch}-{Maschine}-{Systeme}/{Designing} {Hybrid} {Societies}},
	title = {Einführung und Überblick},
	isbn = {978-3-658-29051-1},
	abstract = {Steigende Bedarfe, kürzer werdende Produktlebenszyklen und höhere Variantenvielfalt führen zu einer erhöhten Komplexität in heutigen Produktionsprozessen (Bänziger et al. 2017; Steegmüller und Zürn 2017). Mit dieser immer komplexer werdenden Industrie stoßen vollautomatisierte Industrieroboteranlagen, unter anderem durch hohen Konfigurations- und Umrüstaufwand, an ihre Grenzen (Kahl et al. 2016). Produktionsprozesse, welche der Herausforderung von kleinen Losgrößen und vielen Produktvarianten gegenüberstehen, werden auf Kosten der Produktivität und zu Gunsten der Flexibilität im Allgemeinen als manuelle Arbeitsplätze ausgeführt (Lotter 2012).},
	language = {de},
	booktitle = {Kollaborierende {Roboter} anweisen: {Gestaltungsempfehlungen} für ergonomische {Mensch}-{Roboter}-{Schnittstellen}},
	publisher = {Springer Fachmedien},
	author = {Schleicher, Tim},
	editor = {Schleicher, Tim},
	year = {2020},
	doi = {10.1007/978-3-658-29051-1_1}
}

@book{proff_radikale_2013,
	title = {Radikale {Innovationen} in der {Mobilität}: {Technische} und betriebswirtschaftliche {Aspekte}},
	isbn = {978-3-658-03102-2},
	shorttitle = {Radikale {Innovationen} in der {Mobilität}},
	abstract = {​Radikale Innovationen, insbesondere im Übergang zur Elektromobilität, stellen Wissenschaft und Wirtschaft vor große Herausforderungen. Es bedarf konsequenter und koordinierter Anstrengungen an den Schnittstellen der betriebswirtschaftlichen und ingenieurwissenschaftlichen Forschung, um sie umzusetzen. Im Juni 2013 wurde in Duisburg darüber diskutiert, welche Innovationen erforderlich sind, wie sie gesteuert werden können und welche Mobilitätsstrategien erwartet werden. Der Tagungsband präsentiert dazu die Beiträge des 5. Wissenschaftsforums Mobilität an der Universität Duisburg-Essen.},
	language = {de},
	publisher = {Springer-Verlag},
	author = {Proff, Heike},
	month = dec,
	year = {2013},
	keywords = {Business \& Economics / General, Business \& Economics / Production \& Operations Management, Business \& Economics / Research \& Development},
	page = {248--249}
}

@article{neupert_naturliche_nodate,
	title = {Natürliche {Benutzerschnittstellenkonzepte}},
	url = {ftp://ftp.informatik.uni-stuttgart.de/pub/library/medoc.ustu ttgart_fi/DIP-3587/DIP-3587.pdf},
	abstract = {Neue Technologien und Geräte wie die Microsoft Kinect oder die
Leap Motion ermöglichen die Verwendung von Freihandgesten zur
Mensch-Computer-Interaktion. Im Rahmen dieser Diplomarbeit wird mit Hilfe
dieser Technologien untersucht, wie sich etablierte Interaktionstechniken, wie
Tastatur und Maus oder die Bedienung per Touchscreen durch die Interaktion
mittels Freihandgesten ersetzen lassen. Hierfür werden zwei Szenarien
untersucht: Zum Einen wird die Bedienung einer klassischen Desktop-Applikation
mittels Gesten ermöglicht, zum Anderen wird eine gestenbasierte Interaktion
für einen Fahrkartenautomaten umgesetzt. Für die Desktop-Anwendung soll dabei
ein Expertensytem umgesetzt werden und für den Fahrkartenautomaten eine
möglichst intuitive Steuerung. Das bedeutet, für die Desktop-Applikation
werden komplexere Eingabemodi für spezifische Funktionen der Anwendung
umgesetzt, während die Interaktion des Fahrkartenautomaten selbsterklärend
sein soll. Die beiden entstandenen Lösungen werden anschließend bezüglich
der Benutzbarkeit, der Beanspruchung des Benutzers, der Fehlerrate und der
Interaktionsgeschwindigkeit evaluiert und mit den ersetzten
Interaktionstechniken verglichen.

Abstract New technologies and devices like the Microsoft Kinect or Leap Motion
enable the usage of gestures in the air for human-computer-interaction. Within
the scope of this diploma thesis it will be evaluated whether classic
interaction technologies like keyboard and mouse or touchscreens can be
substituted with gestures in the air interaction in an appropriate way.
Therefore two scenarios will be examined: First a gestural interaction mode for
a common desktop application will be implemented. The second scenario will be a
solution for a ticket machine where the interaction by touchscreen will be
substituted. The interaction mode for the desktop application will be developed
as an expert system, whereas the interaction for the ticket machine needs to be
as intuitive as possible. That is the input modes for the desktop application
will be more complex and fitted to specific application functions. The gestures
in the air interaction for both scenarios will be evaluated regarding
usability, workload, error rate and interaction speed and further will be
compared to the original interaction technologies.},
	author = {Neupert, Andreas}
}

@phdthesis{weidenhausen_mobile_2007,
	address = {Darmstadt},
	type = {phd},
	title = {Mobile {Mixed} {Reality} {Platform}},
	copyright = {lediglich die vom Gesetz vorgesehenen Nutzungsrechte gemäß UrhG},
	abstract = {Die vorliegende Arbeit beschreibt eine Softwareplattform für die Erstellung von Anwendungen im Umfeld mobiler Erweiterter Realitäten. Dabei wurde vor allem auf eine ganzheitliche Erfassung von Erweiterten Realitäten als Prozess, der neben der Laufzeitumgebung auch das Authoring umfasst. Neben der Softwarearchitektur liegt ein weiterer Schwerpunkt der Arbeit auf der Entwicklung speziell auf den Einsatz im mobilen Umfeld angepaßte Techniken der Präsentation und Interaktion.},
	language = {ger},
	school = {Technische Universität},
	author = {Weidenhausen, Jens-Martin},
	month = jan,
	year = {2007},
	pages = {127}
}

@article{krammling_user_2018,
	title = {User {Experience} in der {Gestensteuerung} – {Systematische} {Vergleichsstudie} zwischen {Arm}- und {Fingergestik}},
	abstract = {Anstrengung  ist  Gegenstand  aktueller  Forschungen  in  der Gestensteuerung. Vorangegangene Untersuchungen haben  gezeigt,  dass  Nutzer  kleine  Gesten  bevorzugen,  weil sie weniger anstrengend sind (Liu \& Thomas, 2017).In der vorliegenden Arbeit wird untersucht, inwieweit ein Kontext, in diesem Fall die Bildschirmgröße, die Wahrneh-mung einer Geste beeinflusst. Verschiedene Gestengrö-ßen werden dafür charakterisiert. Im  folgenden  Experiment  haben  45  Testpersonen  ei-nen Spieleprototyp mit drei verschiedenen Gestenpaaren gesteuert. Die  Untersuchungen  haben  jedoch  gezeigt,  dass  die  Bildschirmgröße keinen Einfluss auf die Wahrnehmung der  Anstrengung  einer  Geste  hat.  Kleine  Gesten  wer-den  unabhängig  der  Bildschirmgröße  als  weniger  an-strengend  empfunden.  Außerdem  können  kleine  Gesten  schneller und genauer ausgeführt werden. Des Weiteren wird ein Einfluss der Bewegungsrichtung auf die Ausfüh-rungsgeschwindigkeit vermutet. Insgesamt lässt sich sa-gen, dass kleine Gesten vor einem kleinen Bildschirm eine gute Interaktion ermöglichen und große Gesten die Inter-aktion mit einem großen Bildschirm angenehm gestalten.},
	language = {Deutsch},
	author = {Krammling, Julia},
	year = {2018},
	pages = {28}
}

@misc{nowack_pdf_2017,
	title = {[{PDF}] {Mensch}-{Technik}-{Interaktion} mittels {Freiraumgesten} {\textbar} {Semantic} {Scholar}},
	abstract = {Mit Industrie 4.0 gewinnt die Mensch-Technik-Interaktion deutlich an Stellenwert. Sollen Mensch und Maschine gemeinsam arbeiten, dann sind alternative Interaktionsformen zu entwickeln, z. B. die Gestensteuerung. Die menschliche Kommunikation findet auch akustisch und visuell statt und wird zusammengehorig interpretiert. 
Ausgehend von dem Nutzerverstandnis - Zeigen wird als statische Geste verstanden - wurde eine technisch nutzbare Beschreibung entwickelt, die sich bereits erfolgreich in die Praxis ubertragen lies. Auf Grundlage eines Phasenmodells der Gestenausfuhrung wurden zwei weitere Beschreibungen entwickelt, die den gesamten Gestenzyklus aus Einleitung, Hauptteil, Haltephase und Ausleitung betrachtet. 
Mit den Daten einer Kinect® 2 konnten mit dieser Phasendefinition Erkennungsraten von uber 85 \% realisiert werden. Fur eine Verbesserung der Erkennungsrate ist es zukunftig notwendig, weitere Gesten wie das \&quot;Heranwinken\&quot; zu beschreiben, um sie vom \&quot;Zeigen\&quot; abzugrenzen.},
	language = {en},
	author = {Nowack, Tobias},
	year = {2017},
	note = {Library Catalog: www.semanticscholar.org},
	pages = {68}
}

@misc{erickjpaul_komfort_nodate,
	title = {Komfort - {Mixed} {Reality}},
	url = {https://docs.microsoft.com/de-de/windows/mixed-reality/comfort},
	abstract = {Beim natürlichen Sehen verlässt sich das visuelle System des Menschen auf mehrere Informationsquellen oder „Hinweise“, um dreidimensionale Formen und die relative Position von Objekten zu interpretieren.},
	language = {de-de},
	urldate = {2020-06-18},
	author = {erickjpaul},
	note = {Library Catalog: docs.microsoft.com}
}

@book{boll_mensch_2013,
	title = {Mensch \& {Computer} 2013 – {Tagungsband}: 13. fachübergreifende {Konferenz} für interaktive und kooperative {Medien}},
	isbn = {978-3-486-78122-9},
	shorttitle = {Mensch \& {Computer} 2013 – {Tagungsband}},
	abstract = {Mensch \& Computer ist die jährliche Tagung des Fachbereichs Mensch-Computer-Interaktion der Gesellschaft für Informatik (GI) und die führende Veranstaltung zu diesem Thema im deutschsprachigen Raum. Hier treffen sich Personen aus Wissenschaft und Praxis, um neueste Forschungsergebnisse zu diskutieren, Erfahrungen auszutauschen und neue Produkte und Methoden kennen zu lernen. Die Tagung bietet Einblicke in die Entwicklungen in den Bereichen Usability, User Experience, Mensch-Computer-Interaktion und Gestaltung interaktiver Medien. Die Fachtagung Mensch \& Computer 2013 in Bremen steht unter dem Motto "Interaktive Vielfalt" und richtet das Augenmerk auf die Diversität der Nutzerinnen und Nutzer, die Unterschiedlichkeit ihrer Lebenslagen und Nutzungskontexte sowie der technischen Ausstattung, die sie verwenden. Der Band enthält wissenschaftliche Beiträge zu den auf der Tagung präsentierten Fachvorträgen, Postern und Systemdemonstrationen.},
	language = {de},
	publisher = {Walter de Gruyter},
	author = {Boll, Susanne and Maaß, Susanne and Malaka, Rainer},
	month = aug,
	year = {2013},
	keywords = {Computers / Computer Science, Computers / General, Computers / Human-Computer Interaction (HCI), Computers / Information Technology, Computers / Interactive \& Multimedia, Computers / Networking / General},
	pages = {338--340}
}

@article{bamji__2018,
	title = {From: {C}. {Bamji} et al., “{1Mpixel} 65nm {BSI} {320MHz} {Demodulated} {TOF} {Image} {Sensor} with 3.5μm {Global} {Shutter} {Pixels} and {Analog} {Binning},” {ISSCC} {Deg}. {Tech}. {Papers}, pp. 94-95, {Feb} 2018. {IEEE} {Explore} {Link}: https://ieeexplore.ieee.org/document/8310200/},
	language = {en},
	author = {Bamji, Cyrus S and Mehta, Swati and Thompson, Barry and Elkhatib, Tamer and Akkaya, Onur and Payne, Andrew and Godbaz, John and Fenton, Mike and Prather, Larry and Nagaraja, Satya and Mogallapu, Vishali and McCauley, Rich and Mukadam, Mustansir and Agi, Iskender and Xu, Zhanping and Perry, Travis and Qian, William and Chan, Vei-Han and Ali, Gazi and Ahmed, Muneeb and Mukherjee, Aditya and Nayak, Sheethal and Acharya, Sunil and Kordus, Lou and O'Connor, Pat},
	year = {2018},
	pages = {1--3}
}

@misc{hololens2_hardware_nodate,
	title = {{HoloLens} 2—{Overview}, {Features}, and {Specs} {\textbar} {Microsoft} {HoloLens}},
	url = {https://www.microsoft.com/en-us/hololens/hardware},
	abstract = {HoloLens 2, a new vision for computing. Take a closer look at the specs and features that bring your mixed reality business solution to life.},
	language = {en-us},
	urldate = {2020-06-21},
	note = {Library Catalog: www.microsoft.com}
}

@inproceedings{ghimire_smart_2019,
	title = {Smart {Glove}},
	abstract = {Everyday communication with the hearing population poses a major challenge to those with hearing loss. For this purpose, an automatic sign language recognition system has been developed using Random Forest Classifier as a machine learning algorithm, and to translate the sign alphabets and common words into text and sound. A glove circuit has been designed with flex sensors, 3-axis accelerometer and gyroscope to capture the gestures or signs data. The finger bend data has been obtained from flex sensors on each finger while the accelerometer and gyroscope provided the trajectories of the hand motion. The data from the sensors has been passed through the trained model to recognize the gesture. The main purpose of Smart Glove is to provide an ease of sharing basic ideas, minimize communication gap and an easier collaboration for the hard of hearing people.},
	author = {Ghimire, Adarsh and Kadayat, Bhupendra and Basnet, Aakriti and Shrestha, Anushma and Sharma Dahal, Suramya},
	month = jan,
	year = {2019},
	pages = {1--3}
}

@article{tan_design_2015,
	title = {Design of {Low} {Cost} {Smart} {Insole} for {Real} {Time} {Measurement} of {Plantar} {Pressure}},
	volume = {20},
	doi = {10.1016/j.protcy.2015.07.020},
	abstract = {Real time plantar pressure provides information critical to the understanding of gait mechanics and has a wide range of applications. In this study, smart insoles were designed and developed to measure real time foot plantar pressure. Key features of the insoles included cost-effectiveness, good working pressure detection range, wireless data transfer and real-time data analysis. Calibration of the sensing material was done and the resulting accuracy of the insoles was compared to that of a Kistler force plate, achieving an r2 value of 0.981. Real-time visualization of pressure mapping was incorporated to enable intuitive understanding of relative plantar pressure distribution.},
	journal = {Procedia Technology},
	author = {Tan, Adin and Fuss, Franz and Weizman, Yehuda and Woudstra, Ydwer and Troynikov, Olga},
	month = dec,
	year = {2015},
	pages = {117--119}
}

@misc{encausse_body_nodate,
	title = {Body {Tracking} without {cuDNN}},
	url = {https://feedback.azure.com/forums/920053-azure-kinect-dk/suggestions/38129473-body-tracking-without-cudnn},
	abstract = {The Body Tracking use cuDNN and a powerful gamer PC with an NVidia wheras KInect 1 and 2 worked on simple core I3 / core i5 laptop years ago.


Any chance to have a workaround with a lighter skeletal tracking ?
It seems also the skeletal tracking is less accurate},
	language = {de},
	urldate = {2020-06-21},
	journal = {Customer Feedback for ACE Community Tooling},
	author = {Encausse, Jean-Philippe},
	note = {Library Catalog: feedback.azure.com}
}

@article{kass_ten_2016,
	title = {Ten {Simple} {Rules} for {Effective} {Statistical} {Practice}},
	volume = {12},
	issn = {1553-7358},
	url = {https://dx.plos.org/10.1371/journal.pcbi.1004961},
	doi = {10.1371/journal.pcbi.1004961},
	language = {en},
	number = {6},
	urldate = {2020-06-21},
	journal = {PLOS Computational Biology},
	author = {Kass, Robert E. and Caffo, Brian S. and Davidian, Marie and Meng, Xiao-Li and Yu, Bin and Reid, Nancy},
	editor = {Lewitter, Fran},
	month = jun,
	year = {2016},
	pages = {1--8}
}

@misc{man_sched7_nodate,
	title = {sched(7) - {Linux} manual page},
	url = {https://www.man7.org/linux/man-pages/man7/sched.7.html},
	urldate = {2020-06-22}
}

@misc{lxd_blog_nodate,
	title = {{LXD} 2.0: {Installing} and configuring {LXD} [2/12]},
	shorttitle = {{LXD} 2.0},
	url = {https://ubuntu.com/blog/lxd-2-0-installing-and-configuring-lxd-212},
	abstract = {This is the second blog post in this series about LXD 2.0.Where to get LXD and how to install itThere are many ways to get the latest and greatest LXD. We recommend you use LXD with the latest LXC and Linux kernel to benefit from all its features but we try to degrade gracefully where possible to support older Linux distributions.The Ubun […]},
	language = {en},
	urldate = {2020-06-24},
	journal = {Ubuntu},
	note = {Library Catalog: ubuntu.com}
}

@misc{microsoftazure-kinect-sensor-sdk_installation_nodate,
	title = {microsoft/{Azure}-{Kinect}-{Sensor}-{SDK}},
	url = {https://github.com/microsoft/Azure-Kinect-Sensor-SDK/blob/develop/docs/usage.md},
	abstract = {A cross platform (Linux and Windows) user mode SDK to read data from your Azure Kinect device. - microsoft/Azure-Kinect-Sensor-SDK},
	language = {en},
	urldate = {2020-06-25},
	journal = {GitHub},
	note = {Library Catalog: github.com}
}

@misc{geometry_perpendicular_distance_nodate,
	title = {geometry - {Find} perpendicular distance from point to line in {3D}?},
	url = {https://math.stackexchange.com/questions/1905533/find-perpendicular-distance-from-point-to-line-in-3d},
	urldate = {2020-07-01},
	journal = {Mathematics Stack Exchange},
	note = {Library Catalog: math.stackexchange.com}
}
