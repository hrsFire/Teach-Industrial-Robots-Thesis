Zur Umsetzung der Gestensteuerung eines Industrieroboters wird der Lernroboter WidowX 200, welcher zur InterbotiX X-Serie gehört und von Trossen Robotics hergestellt wird, als Vorlage für einen Industrieroboter verwendet. Mit seinen 5 DOF eignet sich der WidowX 200 für Testzwecke als sichere Alternative zu einem Knickarmroboter. Bei Tests geht im Gegensatz zu einem Industrieroboter eine geringere Gefahr vom WidowX 200 aus, da dieser keine so hohen Kräfte, Geschwindigkeiten und Beschleunigungen wie ein Industrieroboter entwickeln kann. Zudem bietet der \quoteMark{WidowX 200}-Lernroboter den Vorteil, dass es ein umfangreiches Dynamixel-SDK bietet, welches die Integration in ROS und die direkte Kommunikation mit dem Lernroboter einfach gestaltet und daher die Entwicklung des für Gestensteuerung konzipierten Systems drastisch beschleunigt. Für den Gelenk-Modus stellt der Lernroboter auch die Möglichkeit bereit die Gelenke individuell ansprechen und deren Gelenkposition verändern zu können. Die Dynamixel-Servo-Motoren können individuell an die Befürfnisse der Aufgabenstellung angepasst werden, da unter anderem die maximale Geschwindigkeiten und Beschleunigungen der einzelnen Servo-Motoren individuell konfigurierbar sind. Die Reichweite des Roboterarms beträgt in eine Richtung \num{55} cm. Der Arbeitsbereich des WidowX 200 ist kreisförmig und liegt bei einem Durchmesser von \num{110} cm. Im Arbeitsbereich des WidowX 200 sollten sich keine ungewollten Objekte befinden und sichergestellt werden, dass der WidowX 200 in diesem Bereich frei von menschlichen Einflüssen bewegen kann. Anzumerken ist, dass die Wiederholgenauigkeit des WidowX 200 bei \num{1} mm liegt. Für individuelle Aufgabenstellungen kann der Endeffektor jederzeit durch bereits verfügbare oder selbst z.B. durch einen per 3D-Druck erstellten Endeffektor ersetzt werden. Das maximale Tragegewicht des WidowX 200 beträgt 200 g, welches nicht überschritten werden sollte, da ansonsten Fehler bei der Änderung der Gelenkposition auftreten können \cite{noauthor_widowx_200_nodate}.\\

Zur Gestenerkennung wird die Azure Kinect aufgrund der eingebauten Tiefenkamera verwendet. Auf die Azure-Cloud-Integration wird jedoch verzichtet, da das Azure Kinect Body Tracking SDK durch ein DNN eine ausreichend genaue Methode bereitstellt \cite{qm13_azure_kinect_release_notes_nodate} um 32 spezifische Positionen des menschlichen Körpers, zu denen unter anderem die Augen, Schulter, Knie, Daumen und Handspitze zählen, zu erkennen \cite{qm13_azure_joints_nodate}. Zudem wird durch den Einsatz des Azure Kinect Body Tracking SDK die Entwicklung des für Gestensteuerung konzipierten Systems drastisch beschleunigt. Einzelne Finger können daher mit der Azure Kinect nicht erkannt werden. Gesten, welche jedoch die Hand im allgemeinen beinhalten, wie z.B. die Stopp-Geste, sind jedoch unter anderem durch die vorhandenen räumlichen Positionsinformationen realisierbar \cite{noauthor_microsoftazure-kinect-sensor-sdk_2020}.\\

Die Gestensteuerung des WidowX 200, welches auf dem für diese Arbeit erstellten Gesten-Roboter-Framework basiert und als Basis für andere gestengesteuerte Roboter dienen kann, wird näher beschrieben und verschiedene Gesten werden nach der Ergonomie evaluiert. Anschließend werden Gesten, welche mit der Azure Kinect umsetzbar sind, ausgewählt und mit Sicherheitsvorkehrungen kombiniert, welche es verhindern sollen, dass der Roboter sich unbeabsichtigt bewegt.

% https://elib.uni-stuttgart.de/bitstream/11682/9072/1/Schneider-Dissertation-60.pdf
% https://robodk.com/doc/de/Robot-Validation-ISO9283.html

\section{Allgemeine Anforderungen}
Um die Gestensteuerung des WidowX 200 bewerten zu können müssen die allgemeinen Anforderungen an die Software zur Gestensteuerung eines Industrieroboters aufgezeigt werden. Hierzu zählen die funktionalen sowie auch die nichtfunktionalen Anforderungen an die Software zur Gestensteuerung eines Industrieroboters.

\subsection{Funktionale Anforderungen}
Die Anforderungen an die Software zur Gestensteuerung eines Industrieroboter können in die nachfolgenden Punkte gegliedert werden \cite{kircher_it_2006} \cite[2\psq]{brauer_gestenerkennung_nodate}:\\

\begin{compactitem}
    \item \textbf{Nutzung von verbreiteten Paradigmen für die Entwicklung}: Um mehrere Komponenten, welche auf unterschiedlichen Systemen verteilt sein können, miteinander kommunizieren lassen zu können bedarf es eines gemeinsamen Konzepts. Bei Industrierobotern wird hierbei vermehrt ROS eingesetzt, welches es erlaubt ROS-Messages über ein Netzwerkprotokoll verschicken zu können.
    \item \textbf{Standardisiertes Austauschformat}: Der Austausch der Informationen kann bei ROS über sogenannte ROS-Messages erfolgen und beim Speichern und Laden von Informationen in ein standardisiertes Austauschformat, wie z.B. JSON oder XML, übersetzt werden. Hierdurch kann die Interoperabilität zwischen den Systemen gewährleistet werden.
    \item \textbf{Zuverlässigkeit der Übertragung}: Die ROS-Messages müssen unverändert und vollständig über das Netzwerk an den ROS-Master geschickt werden können. Hierfür wird zumeist TCP/IP als Netzwerkprotokoll eingesetzt, welches die vollständigkeit und richtige Reihenfolge der zugrundeliegenden Datenpakete gewährleistet.
    \item \textbf{Zuverlässigkeit der Gestenerkennung}: Die Gestensteuerung sollte eine möglichst kleine Falsch-Positiv-Rate aufweisen um unbeabsichtigte Gesten möglichst gering zu halten und so gefährlichen Situationen entgegenwirken zu können.
    \item \textbf{Echtzeitfähigkeit}: Das System muss sicherstellen, dass es die Informationen in einem gewissen Zeitintervall abarbeiten kann um die Sicherheit des Systems und der beteiligten Menschen gewährleisten zu können.
    \item \textbf{Adaptionsmöglichkeit an verschiedene Tiefenkameras}: Es muss die Möglichkeit bestehen im System die Tiefenkamera durch eine andere Tiefenkamera austauschbar zu machen. Hierbei muss sichergestellt werden, dass die Tiefenkameras die gleichen Schnittstellen verwenden um die gleiche Kommunikation zu ermöglichen.
    \item \textbf{Adaptionsmöglichkeit an verschiedene Industrieroboter}: Durch die schiere Anzahl an Industrierobotern muss es zudem auch möglich sein den Industrieroboter durch einen anderen Industrieroboter, unabhängig von seiner bisher vorhandenen Schnittstellen, ersetzen zu können.
    \item \textbf{Ergonomische Gesten}: Die Gesten müssen leicht erlernbar, einfach anwendbar und leicht zu erlernen sein. Zudem sollte ein längeres Verwenden der Gesten höchstens zu geringen Ermüdungserscheinungen führen und das System von Links- sowie auch Rechtshändern bedienbar sein.
    \item \textbf{Genauigkeit der Erreichung der Zielpose}: Die Zielpose muss je nach Genauigkeit des Industrieroboters über die Gestensteuerung erreichbar sein. Ungenauigkeiten durch die Gestensteuerung, welche aber auch bei Teach Pendants vorhanden sind, sind subjektiver Natur.
    \item \textbf{Sicherheitsvorkehrungen}: Es muss sichergestellt werden können, dass der Industrieroboter jederzeit durch einen Notstop unverzüglich gestoppt werden kann um lebensbedrohliche Situationen vorbeugen zu können.
\end{compactitem}

\subsection{Nichtfunktionale Anforderungen}
Da in dieser Arbeit das Gesten-Roboter-Framework mit und ohne ROS lauffähig sein soll, müssen die Anforderungen an die Schnittstelle zwischen dem Industrieroboter und der Tiefenkamera genauer spezifiziert werden. Die Anforderungen an die Schnittstelle zwischen dem Industrieroboter und der Tiefenkamera sind daher die Folgenden, welche aufgrund von ROS den Anforderungen von Server-Client-Anwendungen entsprechen \cite{osterrieder_komponentenmodelle_2004}:\\

\begin{compactitem}
    \item \textbf{Performanz}: Bei der Kommunikation zwischen den einzelnen Systemen, zu denen die Tiefenkamera und der Industrieroboter zählen, sollte die Anfrage so schnell wie möglich erfolgen, ohne lange Wartezeiten zu benötigen.
    \item \textbf{Zuverlässigkeit}: Die Zuverlässigkeit beschreibt, wie verlässlich ein System seine Aufgaben ausführt. Ausfälle von ROS-Nodes oder sogar des ROS-Masters selbst reduzieren hierbei unter anderem die Zuverlässigkeit des Systems drastisch.
    \item \textbf{Modularität}: Spiegelt den Grad der Aufteilung in Komponenten wider, welche vom eigenen Projekt oder von Dritten wiederverwendet werden können.
    \item \textbf{Erweiterbarkeit}: Bezeichnet die Fähigkeit des Systems durch weitere Komponenten, welche dem System hinzugefügt werden können, angepasst zu werden. Bei ROS können zusätzliche ROS-Packages von Drittanbietern installiert werden, wodurch das System erweitert werden kann.
\end{compactitem}

\section{Einrichtung des Testsystems}
Zur Umsetzung der Gestensteuerung von Industrierobotern wird ROS 1 mit dem Codenamen Melodic Morenia, welches als LTS-Version verfügbar ist und daher Langzeitunterstützung bietet, eingesetzt \cite{noauthor_robot_operating_system_2020}. Als Betriebssystem kommt Ubuntu 18.04 Bionic Beaver zum Einsatz, da dies die neueste unterstützte LTS-Version von Ubuntu darstellt, welche von ROS Melodic Morenia empfohlen wird \cite{noauthor_ros_distributions_nodate}.

\subsection{Linux-Container}
Zur besseren Einsetzbarkeit auf unterschiedlichen Linux-Distributionen wird das genannte Ubuntu 18.04 Bionic Beaver und ROS Melodic Morenia in einem Linux-Container installiert und per Image zur Verfügung gestellt. Der Vorteil durch die Container-Technik stellt hierbei das einfachere und schnellere Deployen, der in dieser Arbeit entwickelten Anwendung zur Gestensteuerung des WidowX 200, dar. Zudem bietet die Container-Technik im Gegensatz zu einem Hypervisor, wie z.B. VMware, VirtualBox oder Hyper-V, den Vorteil, dass kein vollständiges Linux-Betriebssystem virtualisiert werden muss, welches einen impliziten Ressourcen-Overhead, wie z.B. hohe RAM- und CPU-Auslastung, mit sich ziehen würde. Zur Umsetzung der Trennung von Prozessen werden die Kernelnamensräume und für die Ressourcenverwaltung cgroups eingesetzt, welche im Linux-Kernel enthalten sind. Dies führt dazu, dass der Linux-Container auf den gleichen Kernel wie das Host-System zugreifen kann, jedoch aber der Zugriff auf sensible Ressourcen durch den Linux-Kernel beschränkt oder sogar vollständig untersagt wird \cite{noauthor_lxc_2020}. Linux-Container werden auch kurz LXC genannt, welches auch die gleichnamige Bezeichnung für das Userspace-Tool ist um die Linux-Container zu verwalten. Die Erweiterung von LXC wird LXD genannt und ermöglicht die Verwaltung von mehreren LXC-Instanzen über einen System-Daemon, welcher per REST-API angesprochen werden kann. Zudem bietet LXD unter anderem die Möglichkeit Snapshots von Linux-Containern zu erstellen, zu erzeugen, zu starten und zu stoppen \cite{noauthor_lxc_2017}. Für diese Arbeit wird als Host-System, auf dem die LXC-Instanz installiert und ausgeführt wird, Ubuntu 20.04 Focal Fossa verwendet, welches eine LTS-Version von Ubuntu ist und die den Linux-Kernel 5.4 einsetzt. Andere Linux-Distributionen sind grundsätzlich auch möglich solange die für diese Arbeit benötigten Features im Linux-Kernel verfügbar sind. Die benötigten Features können aus der Installationsanleitung, welche sich im Anhang \ref{appendix1:Einrichtung_des_Testsystems} befindet, entnommen werden.

% https://www.techdivision.com/blog/lxc-vs-docker-wir-setzen-bei-techdivision-inzwischen-verstaerkt-auf-lxc.html
% https://www.linux-magazin.de/ausgaben/2015/05/lxd/

\subsection{Simulationsumgebungen}
Zum Durchführen von Tests werden oft Simulationsumgebungen verwendet, da diese den Vorteil bieten, dass kein realer Roboter vorhanden sein muss und dadurch gefährliche Situationen für den Menschen erst gar nicht entstehen können. Während der Entwicklung eines Roboters kann dieser sogar in einer virtuellen Umgebung getestet werden um so das Verhalten und technische Limitierungen des Roboters vor der Herstellung zu ermitteln. Dies spart Zeit und Kosten, da das fertige Produkt erst nach ausführlichen Tests hergestellt wird. Mit Simulationsumgebungen können zudem Tests schneller und effizienter durchgeführt werden, da unter anderem Differenzen zu exakten Zielposen einfacher und genauer als mit manuellen Messungen bestimmt werden können \cite{noauthor_gazebo_nodate}. Zwei der bekanntesten Simulationsumgebungen, welche frei auf dem Markt verfügbar sind und unterschiedliche Roboter unterstützen, sind Gazebo und Coppelia Sim, welches der Nachfolger von vRep darstellt. Beide Simulationsumgebungen sind unter Windows, Linux und macOS verfügbar und bieten die Möglichkeit die standardmäßige Physik-Engine nach belieben mit einer anderen Physik-Engine auszutauschen um z.B. eine genauere Simulation durchführen zu können. Copellia Sim und Gazebo besitzen zudem beide einen Szenen-Editor und bei Coppelia Sim ist zudem im Gegensatz zu Gazebo ein 3D-Model-Editor integriert. Bei Gazebo wird hierdurch eine externe Anwendung benötigt um die 3D-Modelle den jeweiligen Bedürfnissen anpassen zu können. Coppelia Sim ist zudem aufgrund der Stabilität der GUI und der Plugins und der besseren Dokumentation im Gegensatz zu Gazebo zu bevorzugen. Viele Roboter werden aufgrund der ROS-Integration standardmäßig mit Out-of-the-Box-Unterstützung für Gazebo ausgestattet, wodurch bei Verwendung von Coppelia Sim zumeist ein Mehraufwand zum Einrichten des Roboters vonnöten ist. Beide Simulationsumgebungen bieten die Möglichkeit an über ROS-Messages angesprochen zu werden. Hierdurch ist eine Integration in ROS leicht umsetzbar. Copellia Sim und Gazebo bieten jedoch aber auch die Möglichkeit an vollständig ohne ROS verwendet werden zu können und so in beliebigen Softwareumgebungen eingesetzt zu werden \cite{noauthor_v-rep_vs_gazebo_nodate}. In dieser Arbeit wird Gazebo eingesetzt, da bereits der Lernroboter WidowX 200 eine vollständige Gazebo-Unterstützung mitgeliefert bekommt. Die benötigten Schritte zum Einrichten der Simulationsumgebung für den \quoteMark{WidowX 200}-Lernroboter können aus dem Anhang \ref{appendix1:Einrichtung_der_Simulationsumgebung} entnommen werden.

% https://www.ros.org/integration/
% http://gazebosim.org/
% https://www.coppeliarobotics.com/features

\section{Anbindung an ROS}
Da Gazebo standardmäßig eine ROS-Integration bereitstellt müssen nur die ROS-Packages des \quoteMark{WidowX 200}-Lernroboters installiert werden um die Gazebo-Integration einzurichten, wie aus dem Anhang \ref{appendix1:Einrichtung_des_Testsystems} zu entnehmen ist. Danach kann, wie im Anhang \ref{appendix1:Einrichtung_der_Simulationsumgebung} beschrieben wird, die Simulationsumgebung gestartet und für z.B. Tests genutzt werden. Die ROS-Packages des \quoteMark{WidowX 200}-Lernroboters werden von Trossen Robotics entwickelt und der Quellcode kann öffentlich eingesehen werden um eigene Anpassungen daran durchführen zu können. Der \quoteMark{WidowX 200}-Lernroboter kann aufgrund des \quoteMark{InterbotiX}-Nodes von überall aus dem Roboter-Netzwerk angesprochen werden. Zudem ist durch die ROS-Unterstützun des WidowX 200 überhaupt erst möglich MoveIt zu unterstützen. MoveIt ist ein ROS-Package, welches es vor allem ermöglicht Bewegungen zu Planen, die inverse Kinematik zu berechnen oder aber auch Kollisionschecks mit einem Tiefensensor zu ermöglichen \cite{noauthor_moveit_nodate}. Zudem bietet MoveIt eine C++-API an um die ROS-Services zu überspringen und eine höhere Performanz als mit einer vollständigen ROS-Umsetzung zu erhalten \cite{noauthor_moveit_tutorial_nodate}.\\

Für das Azure Kinect Sensor SDK, welches direkten Zugriff auf die Sensoren der Azure Kinect ermöglicht, und das Azure Kinect Body Tracking SDK, welches zur Gestenerkennung eingesetzt werden kann, werden keine ROS-Packages von Microsoft bereitgestellt \cite{tesych_about_azure_kinect_sdks_nodate}. Daher ist es notwendig diese direkt in einen eigenen ROS-Node oder direkt in den ROS-Node der in dieser Arbeit entwickelten Roboter-Gesten-Anwendung zu integrieren. Aufgrund der Komplexität der Gestenerkennung, der Notwendigkeit zur schnellen und sicheren Reaktion auf die Gesten und der Möglichkeit von sehr schnell aufeinander folgenden Gesten und Bewegungsabläufen der Hände wurde entschieden die Gestenerkennung über eine C++-Schnittstelle bereitzustellen um möglichst jederzeit sicherstellen zu können, dass die Nutzereingaben schnell genug an die Steuereinheit übermittelt werden können. Zudem bietet es bei der Messung der Latenz der Übertragung mit und ohne ROS-Anbindung den Vorteil, dass schnell darauf geschlossen werden kann wo der Flaschenhals im System liegt. Dies wäre mit sehr vielen selbst erstellten und verteilten ROS-Nodes nur sehr schwer bis überhaupt nicht einsehbar, da das System zu komplex werden würde \cite{noauthor_why_dont_we_use_ros_nodate}. Der ROS-Node zur Gestenerkennung muss durch diesen Ansatz nur noch die benötigten Roboter-Befehle per MoveIt oder über die ROS-Schnittstelle des Industrieroboters an die Motoren des Industrieroboters senden um Gelenkbewegungen auslösen zu können.

\section{Gesten}
% https://www.uni-bremen.de/fileadmin/user_upload/sites/artec/Publikationen/artec_Paper/042_paper.pdf
% S. 3
% brauer_gestenerkennung_nodate

\subsection{Arten von Gesten}
\textcolor{red}{TODO:\\
Welche mögliche Gesten gibt es?
}

\subsection{Auswahl anhand der Ergonomie}
\textcolor{red}{TODO:\\
Welche Gesten sind zu empfehlen, welche sollten eher nicht gewählt werden? Gibt es vielleicht Bilder?\\
Begründung der Implementierten Gesten für die jeweiligen Aktionen (Joint Mode, ...) und warum diese sinnvoll sind
}

\subsection{Sicherheitsvorkehrungen}
\textcolor{red}{TODO:\\
Notstop-Handgerät\\
Berechnungen
}

\section{Aufbau des Gesten-Roboter-Frameworks}
\textcolor{red}{TODO:\\
Gesten-Roboter-Framework mit UML erklären\\
Wie kann es gestartet werden?\\
Was sind die Vorraussetzungen um das Backend zu starten?\\
ROS-Dependency Tree\\
Klassenhierarchie und Vererbungsmöglichkeiten (Erweiterbar für jede Arte von Roboter \& Tiefenkamera, welche mindestens die folgenden Anforderungen erfüllt ..., ...)\\
UML Diagramm (Regelkreis, Besprechung, ...)\\
WidowX 200 Packages angepasst für direkte Kommunikation, da gleiche Schnittstellen für Vergleiche besser geeignet sind
}

\section{Messvoraussetzungen}
\textcolor{red}{TODO:\\
Durchsatz, Latenzen, ...\\
Informationen aus Datenblätter\\
Zeit zur Erkennung von Gesten (Azure Kinect Body Tracking SDK: beinhaltet Latenz von Aussenden des Infrarot-Lichtimpuls bis zum Empfang zur Absorption des Lichtimpuls, durch Belichtungszeit bis hin zur Latenz über das \quoteMark{USB 2.0}-Kabel)?\\
Mit Simulationsumgebung durchführen
}
