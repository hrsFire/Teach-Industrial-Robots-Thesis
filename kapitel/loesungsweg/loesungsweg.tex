Zur Umsetzung der Gestensteuerung eines Industrieroboters wird der Lernroboter WidowX 200 von Trossen Robotics als Vorlage für einen Industrieroboter verwendet. Mit seinen 5 DOF eignet sich der WidowX 200 für Testzwecke als sichere Alternative zu einem Knickarmroboter. Bei Tests geht im Gegensatz zu einem Industrieroboter eine geringere Gefahr vom WidowX 200 aus, da dieser keine so hohen Kräfte, Geschwindigkeiten und Beschleunigungen wie ein Industrieroboter entwickeln kann. Zudem bietet der WidowX 200 Lernroboter den Vorteil, dass es ein umfangreiches Dynamixel-SDK bietet, welches die Integration in ROS und die direkte Kommunikation mit dem Lernroboter einfach gestaltet und daher die Entwicklung des für Gestensteuerung konzipierten Systems drastisch beschleunigt. Für den Gelenk-Modus stellt der Lernroboter auch die Möglichkeit bereit die Gelenke individuell ansprechen und deren Gelenkposition verändern zu können. Die Dynamixel-Servo-Motoren können individuell an die Befürfnisse der Aufgabenstellung angepasst werden, da unter anderem die maximale Geschwindigkeiten und Beschleunigungen der einzelnen Servo-Motoren individuell konfigurierbar sind. Die Reichweite des Roboterarms beträgt in eine Richtung \num{55} cm. Der Arbeitsbereich des WidowX 200 ist kreisförmig und liegt bei einem Durchmesser von \num{110} cm. Im Arbeitsbereich des WidowX 200 sollten sich keine ungewollten Objekte befinden und sichergestellt werden, dass der WidowX 200 in diesem Bereich frei von menschlichen Einflüssen bewegen kann. Anzumerken ist, dass die Wiederholgenauigkeit des WidowX 200 bei \num{1} mm liegt. Für individuelle Aufgabenstellungen kann der Endeffektor jederzeit durch bereits verfügbare oder selbst z.B. durch einen per 3D-Druck erstellten Endeffektor ersetzt werden. Das maximale Tragegewicht des WidowX 200 beträgt 200 g, welches nicht überschritten werden sollte, da ansonsten Fehler bei der Änderung der Gelenkposition auftreten können \cite{noauthor_widowx_200_nodate}.\\

Zur Gestenerkennung wird die Azure Kinect aufgrund der eingebauten Tiefenkamera verwendet. Auf die Azure-Cloud-Integration wird jedoch verzichtet, da das Bodytracking SDK durch ein DNN eine ausreichend genaue Methode bereitstellt \cite{qm13_azure_kinect_release_notes_nodate} um 32 spezifische Positionen des menschlichen Körpers, zu denen unter anderem die Augen, Schulter, Knie, Daumen und Handspitze zählen, zu erkennen \cite{qm13_azure_joints_nodate}. Zudem wird durch den Einsatz des Bodytracking SDK die Entwicklung des für Gestensteuerung konzipierten Systems drastisch beschleunigt. Einzelne Finger können daher mit der Azure Kinect nicht erkannt werden. Gesten, welche jedoch die Hand im allgemeinen beinhalten, wie z.B. die Stopp-Geste, sind jedoch unter anderem durch die vorhandenen räumlichen Positionsinformationen realisierbar \cite{noauthor_microsoftazure-kinect-sensor-sdk_2020}.\\

Die Gestensteuerung des WidowX 200, welches auf dem für diese Arbeit erstellten Gesten-Roboter-Framework basiert und als Basis für andere gestengesteuerte Roboter dienen kann, wird näher beschrieben und verschiedene Gesten werden nach der Ergonomie evaluiert. Anschließend werden Gesten, welche mit der Azure Kinect umsetzbar sind, ausgewählt und mit Sicherheitsvorkehrungen kombiniert, welche es verhindern sollen, dass der Roboter sich unbeabsichtigt bewegt.

% https://elib.uni-stuttgart.de/bitstream/11682/9072/1/Schneider-Dissertation-60.pdf
% https://robodk.com/doc/de/Robot-Validation-ISO9283.html



%-----------------------------------------------

% LXC: https://serverfault.com/questions/630220/how-do-i-configure-lxc-to-allow-the-use-of-sched-rr-in-a-container
% Scheduler wechseln:
% cat /sys/block/sda/queue/scheduler
% https://www.thomas-krenn.com/de/wiki/Linux_I/O_Scheduler#Deadline


%--------------
%sudo apt install schedtool # http://manpages.ubuntu.com/manpages/xenial/man8/schedtool.8.html
%
%"A privileged user can change the priority policy of a process with the schedtool program[7]:ln 326, 373 or it is done by a program itself.[7]:ln 336 The priority class can be manipulated at the code level with a syscall like sched_setscheduler only available to root,[11] which schedtool uses.[12]"
%# https://en.wikipedia.org/wiki/Brain_Fuck_Scheduler
%sudo chrt -p $(pidof -s bash)


% "the default scheduler is CFS, the "Completely Fair Scheduler"
% http://manpages.ubuntu.com/manpages/focal/en/man7/sched.7.html
% http://manpages.ubuntu.com/manpages/eoan/en/man7/sched.7.html
% https://en.wikipedia.org/wiki/Completely_Fair_Scheduler
% https://www.kernel.org/doc/html/latest/scheduler/sched-design-CFS.html
%-------------

% https://www.researchgate.net/publication/331290349_The_real-time_linux_kernel_A_survey_on_Preempt_RT

% -----------


% sudo chrt -d --sched-runtime 1000000 --sched-deadline 5000000 --sched-period 5000000 -p  0 57802
% https://access.redhat.com/solutions/3742421
% http://manpages.ubuntu.com/manpages/cosmic/de/man1/chrt.1.html
% https://lwn.net/Articles/743740/
% # nanoseconds for the parameters

% TODO: Wie lange ist für uns Echtzeit? -> Messungen!

%-----------------------------------------------


% Dead Man's Switch: irgendetwas in der Hand halten?
% Wenn sich keine Person vor dem Tiefensesor befindet, dann werden auch keine Bewegungen ausgeführt.

% verwendeter Tiefensensor-Modus -> warum?

% Intel Real Sense Camera ZR300

\section{Allgemeine Anforderungen}
Um die Gestensteuerung des WidowX 200 bewerten zu können müssen die allgemeinen Anforderungen an die Software zur Gestensteuerung eines Industrieroboters aufgezeigt werden. Hierzu zählen die funktionalen sowie auch die nichtfunktionalen Anforderungen an die Software zur Gestensteuerung eines Industrieroboters.
% weiche Echtzeitfähigkeit
% Durchsatz, Latenzen, ...

\subsection{Funktionale Anforderungen}
Die Anforderungen an die Software zur Gestensteuerung eines Industrieroboter können in die nachfolgenden Punkte gegliedert werden \cite{kircher_it_2006} \cite[2\psq]{brauer_gestenerkennung_nodate}:\\

\begin{compactitem}
    \item \textbf{Nutzung von verbreiteten Paradigmen für die Entwicklung}: Um mehrere Komponenten, welche auf unterschiedlichen Systemen verteilt sein können, miteinander kommunizieren lassen zu können bedarf es eines gemeinsamen Konzepts. Bei Industrierobotern wird hierbei vermehrt ROS eingesetzt, welches es erlaubt ROS-Messages über ein Netzwerkprotokoll verschicken zu können.
    \item \textbf{Standardisiertes Austauschformat}: Der Austausch der Informationen kann bei ROS über sogenannte ROS-Messages erfolgen und beim Speichern und Laden von Informationen in ein standardisiertes Austauschformat, wie z.B. JSON oder XML, erfolgen. Hierdurch kan die Interoperabilität zwischen den Systemen gewährleistet werden.
    \item \textbf{Zuverlässigkeit der Übertragung}: Die ROS-Messages müssen unverändert und vollständig über das Netzwerk an den ROS-Master geschickt werden können. Hierfür wird zumeist TCP/IP als Netzwerkprotokoll eingesetzt, welches die richtige Reihenfolge der zugrundeliegenden Datenpakete gewährleistet.
    \item \textbf{Zuverlässigkeit der Gestenerkennung}: Die Gestensteuerung sollte eine möglichst kleine Falsch-Positiv-Rate aufweisen um unbeabsichtigte Gesten möglichst gering zu halten und so gefährlichen Situationen entgegenwirken zu können.
    \item \textbf{Echtzeitfähigkeit}: Das System muss sicherstellen, dass es die Informationen in einem gewissen Zeitintervall abarbeiten kann um die Sicherheit des Systems und der beteiligten Menschen gewährleisten zu können.
    \item \textbf{Adaptionsmöglichkeit an verschiedene Tiefenkameras}: Es muss die Möglichkeit bestehen die Tiefenkamera durch eine andere Tiefenkamera austauschbar zu machen. Hierbei muss sichergestellt werden, dass die Tiefenkameras die gleichen Schnittstellen verwenden um die Kommunikation zu ermöglichen.
    \item \textbf{Adaptionsmöglichkeit an verschiedene Industrieroboter}: Durch die schiere Anzahl an Industrierobotern muss es zudem auch möglich sein den Industrieroboter durch einen anderen Industrieroboter unabhängig von seiner bisher vorhandenen Schnittstellen ersetzen zu können.
    \item \textbf{Ergonomische Gesten}: Die Gesten müssen leich erlernbar, einfach anwendbar und leicht zu erlernen sein. Zudem sollte ein längeres Verwenden der Gesten nur zu geringen Ermüdungserscheinungen führen und von Links- sowie auch Rechtshändern ausführbar sein.
    \item \textbf{Genauigkeit der Erreichung der Zielpose}: Die Zielpose muss je nach Genauigkeit des Industrieroboters über die Gestensteuerung erreichbar sein. Ungenauigkeiten durch die Gestensteuerung, welche aber auch bei Teach Pendants vorhanden sind, sind subjektiver Natur.
    \item \textbf{Sicherheitsvorkehrungen}: Es muss sichergestellt werden können, dass der Industrieroboter jederzeit durch einen Notstop unverzüglich gestoppt werden kann um lebensbedrohliche Situationen vorbeugen zu können.
\end{compactitem}

\subsection{Nichtfunktionale Anforderungen}
Da in dieser Arbeit das Gesten-Roboter-Framework mit und ohne ROS lauffähig sein soll, müssen die Anforderungen an die Schnittstelle zwischen dem Industrieroboter und der Tiefenkamera genauer spezifiziert werden. Die Anforderungen an die Schnittstelle zwischen dem Industrieroboter und der Tiefenkamera sind daher die Folgenden, welche aufgrund von ROS den Anforderungen von Server-Client-Anwendungen entsprechen \cite{osterrieder_komponentenmodelle_2004}:\\

\begin{compactitem}
    \item \textbf{Performanz}: Bei der Kommunikation zwischen den einzelnen Systemen, zu denen die Tiefenkamera und der Industrieroboter zählen, sollte die Anfrage so schnell wie möglich erfolgen, ohne lange Wartezeiten zu benötigen.
    \item \textbf{Zuverlässigkeit}: Die Zuverlässigkeit beschreibt, wie verlässlich ein System seine Aufgaben ausführt. Ausfälle von ROS-Nodes oder sogar des ROS-Masters reduzieren hierbei unter anderem die Zuverlässigkeit des Systems drastisch.
    \item \textbf{Modularität}: Spiegelt den Grad der Aufteilung in Komponenten wider, welche vom eigenen Projekt oder von Dritten wiederverwendet werden können.
    \item \textbf{Erweiterbarkeit}: Bezeichnet die Fähigkeit des Systems durch weitere Komponenten, welche dem System hinzugefügt werden können, angepasst zu werden. Bei ROS können zusätzliche ROS-Packages von Drittanbietern installiert werden, wodurch das System erweitert wird.
\end{compactitem}

\section{Einrichtung des Testsystems}
\textcolor{red}{TODO:\\
Linux-Container\\
ROS\\
\\
Was ist ein Linux-Container? Vorteile?\\
% https://www.techdivision.com/blog/lxc-vs-docker-wir-setzen-bei-techdivision-inzwischen-verstaerkt-auf-lxc.html
% https://www.webhod.de/lxc-und-lxd-was-sind-linux-container/
% https://www.linux-magazin.de/ausgaben/2015/05/lxd/
\\
Anhang: Installationsanleitung
}


\subsection{Simulationsumgebungen}
\textcolor{red}{TODO:\\
Gazebo, vRep %, Coppelia Sim, ABB, ...
https://www.ros.org/integration/
}


\section{Anbindung an ROS}
\textcolor{red}{TODO:\\
Anbindung an ROS
}


\section{Einbinden von Nicht-ROS-Komponenten}
\textcolor{red}{TODO:\\
WidowX 200 (direkte Verbindung) \& Azure Kinect SDKs\\
Probleme und Besonderheiten
}


\subsection{ROS-Packages}
\textcolor{red}{TODO:\\
Verwendete ROS Packages
}


\section{Gesten}
% https://www.uni-bremen.de/fileadmin/user_upload/sites/artec/Publikationen/artec_Paper/042_paper.pdf
% S. 3
% brauer_gestenerkennung_nodate


\subsection{Arten von Gesten}
\textcolor{red}{TODO:\\
Welche mögliche Gesten gibt es?
}

\subsection{Auswahl anhand der Ergonomie}
\textcolor{red}{TODO:\\
Welche Gesten sind zu empfehlen, welche sollten eher nicht gewählt werden? Gibt es vielleicht Bilder?\\
Begründung der Implementierten Gesten für die jeweiligen Aktionen (Joint Mode, ...) und warum diese sinnvoll sind
}

\subsection{Sicherheitsvorkehrungen}
\textcolor{red}{TODO:\\
Notstop-Handgerät\\
Berechnungen
}


\section{Aufbau des Gesten-Roboter-Frameworks}
\textcolor{red}{TODO:\\
Gesten-Roboter-Framework mit UML erklären\\
Wie kann es gestartet werden?\\
Was sind die Vorraussetzungen um das Backend zu starten?\\
ROS-Dependency Tree\\
Klassenhierarchie und Vererbungsmöglichkeiten (Erweiterbar für jede Arte von Roboter \& Tiefenkamera, welche mindestens die folgenden Anforderungen erfüllt ..., ...)\\
UML Diagramm (Regelkreis, Besprechung, ...)
}


\section{Messvoraussetzungen}
\textcolor{red}{TODO:\\
Durchsatz, Latenzen, ...\\
Informationen aus Datenblätter\\
Zeit zur Erkennung von Gesten (Bodytracking SDK: beinhaltet Latenz von Aussenden des Infrarot-Lichtimpuls bis zum Empfang zur Absorption des Lichtimpuls, durch Belichtungszeit bis hin zur Latenz über das \quoteMark{USB 2.0}-Kabel)?\\
Mit Simulationsumgebung durchführen
}
