Zur Umsetzung der Gestensteuerung eines Industrieroboters wird der Lernroboter WidowX 200 von Trossen Robotics als Vorlage für einen Industrieroboter verwendet. Mit seinen 5 DOF eignet sich der WidowX 200 für Testzwecke als sichere Alternative zu einem Knickarmroboter. Bei Tests geht im Gegensatz zu einem Industrieroboter eine geringere Gefahr vom WidowX 200 aus, da dieser keine so hohen Kräfte, Geschwindigkeiten und Beschleunigungen wie ein Industrieroboter entwickeln kann. Zudem bietet der WidowX 200 Lernroboter den Vorteil, dass es ein umfangreiches Dynamixel-SDK bietet, welches die Integration in ROS und die direkte Kommunikation mit dem Lernroboter einfach gestaltet und daher die Entwicklung des für Gestensteuerung konzipierten Systems drastisch beschleunigt. Für den Gelenk-Modus stellt der Lernroboter auch die Möglichkeit bereit die Gelenke individuell ansprechen und deren Gelenkposition verändern zu können. Die Dynamixel-Servo-Motoren können individuell an die Befürfnisse der Aufgabenstellung angepasst werden, da unter anderem die maximale Geschwindigkeiten und Beschleunigungen der einzelnen Servo-Motoren individuell konfigurierbar sind. Die Reichweite des Roboterarms beträgt in eine Richtung \num{55} cm. Der Arbeitsbereich des WidowX 200 ist kreisförmig und liegt bei einem Durchmesser von \num{110} cm. Im Arbeitsbereich des WidowX 200 sollten sich keine ungewollten Objekte befinden und sichergestellt werden, dass der WidowX 200 in diesem Bereich frei von menschlichen Einflüssen bewegen kann. Anzumerken ist, dass die Wiederholgenauigkeit des WidowX 200 bei \num{1} mm liegt. Für individuelle Aufgabenstellungen kann der Endeffektor jederzeit durch bereits verfügbare oder selbst z.B. durch einen per 3D-Druck erstellten Endeffektor ersetzt werden. Das maximale Tragegewicht des WidowX 200 beträgt 200 g, welches nicht überschritten werden sollte, da ansonsten Fehler bei der Änderung der Gelenkposition auftretten können \cite{noauthor_widowx_200_nodate}.\\

Zur Gestenerkennung wird die Azure Kinect aufgrund der eingebauten Tiefenkamera verwendet. Auf die Azure-Cloud-Integration wird jedoch verzichtet, da das Bodytracking SDK durch ein DNN eine ausreichend genaue Methode bereitstellt \cite{qm13_azure_kinect_release_notes_nodate} um 32 spezifische Positionen des menschlichen Körpers, zu denen unter anderem die Augen, Schulter, Knie, Daumen und Handspitze zählen, zu erkennen \cite{qm13_azure_joints_nodate}. Zudem wird durch den Einsatz des Bodytracking SDK die Entwicklung des für Gestensteuerung konzipierten Systems drastisch beschleunigt. Einzelne Finger können daher mit der Azure Kinect nicht erkannt werden. Gesten, welche jedoch die Hand im allgemeinen beinhalten, wie z.B. die Stopp-Geste, sind jedoch unter anderem durch die vorhandenen räumlichen Positionsinformationen realisierbar \cite{noauthor_microsoftazure-kinect-sensor-sdk_2020}.\\

Die Gestensteuerung des WidowX 200, welches auf dem für diese Arbeit erstellten Gesten-Roboter-Framework basiert und als Basis für andere gestengesteuerte Roboter dienen kann, wird näher beschrieben und verschiedene Gesten werden nach der Ergonomie evaluiert. Anschließend werden Gesten, welche mit der Azure Kinect umsetzbar sind, ausgewählt und mit Sicherheitsvorkehrungen kombiniert, welche es verhindern sollen, dass der Roboter sich unbeabsichtigt bewegt.

% https://elib.uni-stuttgart.de/bitstream/11682/9072/1/Schneider-Dissertation-60.pdf
% https://robodk.com/doc/de/Robot-Validation-ISO9283.html



%-----------------------------------------------

% LXC: https://serverfault.com/questions/630220/how-do-i-configure-lxc-to-allow-the-use-of-sched-rr-in-a-container
% Scheduler wechseln:
% cat /sys/block/sda/queue/scheduler
% https://www.thomas-krenn.com/de/wiki/Linux_I/O_Scheduler#Deadline


%--------------
%sudo apt install schedtool # http://manpages.ubuntu.com/manpages/xenial/man8/schedtool.8.html
%
%"A privileged user can change the priority policy of a process with the schedtool program[7]:ln 326, 373 or it is done by a program itself.[7]:ln 336 The priority class can be manipulated at the code level with a syscall like sched_setscheduler only available to root,[11] which schedtool uses.[12]"
%# https://en.wikipedia.org/wiki/Brain_Fuck_Scheduler
%sudo chrt -p $(pidof -s bash)


% "the default scheduler is CFS, the "Completely Fair Scheduler"
% http://manpages.ubuntu.com/manpages/focal/en/man7/sched.7.html
% http://manpages.ubuntu.com/manpages/eoan/en/man7/sched.7.html
% https://en.wikipedia.org/wiki/Completely_Fair_Scheduler
% https://www.kernel.org/doc/html/latest/scheduler/sched-design-CFS.html
%-------------

% https://www.researchgate.net/publication/331290349_The_real-time_linux_kernel_A_survey_on_Preempt_RT

% -----------


% sudo chrt -d --sched-runtime 1000000 --sched-deadline 5000000 --sched-period 5000000 -p  0 57802
% https://access.redhat.com/solutions/3742421
% http://manpages.ubuntu.com/manpages/cosmic/de/man1/chrt.1.html
% https://lwn.net/Articles/743740/
% # nanoseconds for the parameters

% TODO: Wie lange ist für uns Echtzeit? -> Messungen!

%-----------------------------------------------


% Dead Man's Switch: irgendetwas in der Hand halten?
% Wenn sich keine Person vor dem Tiefensesor befindet, dann werden auch keine Bewegungen ausgeführt.

% verwendeter Tiefensensor-Modus -> warum?

% Intel Real Sense Camera ZR300

\section{Allgemeine Anforderungen}
Um die Gestensteuerung des WidowX 200 bewerten zu können müssen die allgemeinen Anforderungen an die Gestensteuerung eines Industrieroboters aufgezeigt werden. Hierzu zählen die funktionalen sowie auch die nichtfunktionalen Anforderungen an die Gestensteuerung eines Industrieroboters.
% weiche Echtzeitfähigkeit
% Durchsatz, Latenzen, ...

\subsection{Funktionale Anforderungen}
Generell können die Anforderungen an die Gestensteuerung für einen Industrieroboter in die nachfolgenden Punkte gegliedert werden:

\subsection{Nichtfunktionale Anforderungen}


\section{Einrichtung des Testsystems}
\textcolor{red}{TODO:\\
Linux-Container\\
ROS\\
\\
Was ist ein Linux-Container? Vorteile?\\
% https://www.techdivision.com/blog/lxc-vs-docker-wir-setzen-bei-techdivision-inzwischen-verstaerkt-auf-lxc.html
% https://www.webhod.de/lxc-und-lxd-was-sind-linux-container/
% https://www.linux-magazin.de/ausgaben/2015/05/lxd/
\\
Anhang: Installationsanleitung
}


\subsection{Simulationsumgebungen}
\textcolor{red}{TODO:\\
Gazebo, vRep %, Coppelia Sim, ABB, ...
https://www.ros.org/integration/
}


\section{Anbindung an ROS}
\textcolor{red}{TODO:\\
Anbindung an ROS
}


\section{Einbinden von Nicht-ROS-Komponenten}
\textcolor{red}{TODO:\\
WidowX 200 (direkte Verbindung) \& Azure Kinect SDKs\\
Probleme und Besonderheiten
}


\subsection{ROS-Packages}
\textcolor{red}{TODO:\\
Verwendete ROS Packages
}


\section{Gesten}


\subsection{Arten von Gesten}
\textcolor{red}{TODO:\\
Welche mögliche Gesten gibt es?
}

\subsection{Auswahl anhand der Ergonomie}
\textcolor{red}{TODO:\\
Welche Gesten sind zu empfehlen, welche sollten eher nicht gewählt werden? Gibt es vielleicht Bilder?\\
Begründung der Implementierten Gesten für die jeweiligen Aktionen (Joint Mode, ...) und warum diese sinnvoll sind
}

\subsection{Sicherheitsvorkehrungen}
\textcolor{red}{TODO:\\
Notstop-Handgerät\\
Berechnungen
}


\section{Aufbau des Gesten-Roboter-Frameworks}
\textcolor{red}{TODO:\\
Gesten-Roboter-Framework mit UML erklären\\
Wie kann es gestartet werden?\\
Was sind die Vorraussetzungen um das Backend zu starten?\\
ROS-Dependency Tree\\
Klassenhierarchie und Vererbungsmöglichkeiten (Erweiterbar für jede Arte von Roboter \& Tiefenkamera, welche mindestens die folgenden Anforderungen erfüllt ..., ...)\\
UML Diagramm (Regelkreis, Besprechung, ...)
}


\section{Messvoraussetzungen}
\textcolor{red}{TODO:\\
Durchsatz, Latenzen, ...\\
Informationen aus Datenblätter\\
Zeit zur Erkennung von Gesten (Bodytracking SDK: beinhaltet Latenz von Aussenden des Infrarot-Lichtimpuls bis zum Empfang zur Absorption des Lichtimpuls, durch Belichtungszeit bis hin zur Latenz über das \quoteMark{USB 2.0}-Kabel)?\\
Mit Simulationsumgebung durchführen
}
