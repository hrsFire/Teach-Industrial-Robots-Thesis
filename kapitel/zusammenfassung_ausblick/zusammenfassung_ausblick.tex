\section{Zusammenfassung}

\textcolor{red}{TODO}
% Azure Kinect: 
%    Stärken der Kinect: Keine Notwendigkeit einer Kalibrierpose, Posenberechnung ohne getragene Hardware
% Problem: immer in Richtung der Azure Kinect schauen -> diese ist statisch


Da die Zeit von unter 50 ms, welches für ein Teach Pendant empfohlen wird \cite[55]{prassler_advances_2004}, nicht eingehalten werden kann  muss die Berechnung des neuronalen Netzwerks der Gestenerkennung noch schneller werden bzw. auf speziell darauf ausgelegter Hardware, wie z.B. FPGAs, ausgeführt werden.

\section{Ausblick}
\textcolor{red}{TODO}

% ROS ist nicht das Allheilmittel sonder eine mögliche Implementierung die sich erst noch im industriellen Einsatz behaupten muss über die Jahre \cite{noauthor_why_dont_we_use_ros_nodate}

% Was könnte in Zukunft besser gemacht werden?

% Gibt es bessere Alternativen? HoloLens 2 da näher? -> ungenauigkeit auf längere Distanz; Datenhandschuh -> mobiler

% Auch bezüglich der bisher erzielten Erkennungsratensind  noch  Verbesserungen  notwendig,  damit  eine  ausreichende  Akzeptanz  bei  den  Benutzern  erreichtwird.

% ROS den Ansprüchen von Industrierobotern gerecht wird.

% Erkennungsrate der Gestenerkennung

% Gibt es weiterführende Themen, welche behandelt werden könnten?
Der CPU-Modus des Azure Kinect Body Tracking SDKs ist mit einer gemessenen Latenz von 300 ms nutzbar, jedoch aber zeitkritisch aus sicherheitstechnischer Sicht. Aus diesem Grund ist zu hoffen, dass das Azure Kinect Body Tracking SDK neben der CUDA basierten Grafikkartenbeschleunigung, welche nur auf Nvidia basierten Grafikkarten verfügbar ist \cite{encausse_body_nodate}, eine herstellerunabhängige Implementierung erhält. Dies würde vor allem die Performanz der Gestenerkennung, die freie Wahl der Rechnerkomponenten ermöglichen und zudem den Wettbewerb zwischen den Herstellern fördern.\\

Im Vergleich zur Kinect 2, welche eine \num{0,3}-Megapixel-Tiefenkamera verbaut hat, ist die Azure Kinect, welche eine 1-Megapixel-Tiefenkamera besitzt, bereits eine deutliche Weiterentwicklung zu ihrem Vorgängermodell. Nichtsdestotrotz ist hier jedoch durch den großen Spring von einer \num{0,3}- auf eine 1-Megapixel-Auflösung noch genügend Verbesserungspotenziall vorhanden um noch höhere Auflösungen erreichen zu können \cite{bamji__2018}. Mit einer höheren Auflösung der Tiefenkamera wäre es möglich die Gesten noch genauer zu erkennen und die False-Positive-Rate noch weiter zu verringern. Mittels Eye-Tracking, welches z.B. in der HoloLens 2 verbaut ist \cite{hololens2_hardware_nodate}, könnte man die Sicherheit der bedienenden Person zusätzlich erhöhen und die Gestenerkennung noch zuverlässiger gestalten. Hiermit könnte man unter anderem erkennen ob die bedienende Person Ermüdungserscheinungen aufweist und daher besser eine Pause einlegen sollte oder sogar nicht mehr bei Bewusstsein ist, da die bedienende Person z.B. ungewollt auf dem Boden liegt.\\

Es wäre zudem denkbar, dass die Umgebung des Industrieroboters durch weitere Tiefenkameras abgescannt werden könnte um eine Kollisionserkennung für den Industrieroboter zu realisieren. Hierdurch könnte der Industrieroboter auf Hindernisse reagieren und so Personen sowie auch anderen Objekte frühzeitig zu erkennen. Dadurch könnte die Sicherheit des Systems höchstwahrscheinlich zusätzlich verbessert werden und die Gefahr von kritischen Situationen nochmals verringert werden. Durch die Verwendung von mehreren im Raum verteilten Tiefenkameras könnten zudem tote Winkel verringert und die Bedienung der Roboter-Gesten-Anwendung aus verschiedenen Blickrichtungen fehlerfreier ermöglicht werden.\\

Weiteres Forschungspotenzial besteht auch im Bereich der Sicherheit und Ergonomie der in dieser Arbeit entwickelten Roboter-Gesten-Anwendung. Hierbei könnte erforscht werden wie gut sich z.B. smarte Fußeinlagesohlen zur Sicherheits- und Ergonomiesteigerung eignen würden. Hierdurch würden die Hände zur Gestensteuerung frei bleiben und es könnte womöglich eine Art von \quoteMark{Dead Man's Switch} mit einer smarten Fußeinlagesohle realisiert werden. Hierdurch wäre es vermutlich machbar sehr schnelle und reflexartige Druckverteilungen und Bewegungen zu Erkennen und den Industrieroboter bei dieser Art von Bewegung zu stoppen. Zu wenig oder kein Druck auf den Fußeinlagesohlen könnten mehrere Gründe haben, da z.B. die Sohlen abgezogen wurden oder die bedienende Person ungewollt auf dem Boden liegt. Das Starten der Gestenerkennung könnte womöglich auch durch eine korrekt ausgeführte Kombination aus Fußbewegungen realisiert werden \cite{tan_design_2015}. Eine andere Möglichkeit würde darin bestehen einen smarten Handschuh mit einem Beschleunigungssensor und einem Gyroskop zu verwenden, welcher zu schnelle Bewegungen erkennen könnte und die Bewegung des Industrieroboters bei auffälligen Bewegungen anhält \cite{ghimire_smart_2019}. Zur Realisierung könnte ein künstliches neuronales Netzwerk auf diese auffälligen Bewegungen trainiert werden.

% Vergleich zu Plattform fürs Teachen
