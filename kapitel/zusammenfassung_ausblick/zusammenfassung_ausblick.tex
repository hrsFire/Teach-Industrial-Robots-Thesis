\section{Zusammenfassung}
Es konnte aufgezeigt werden, dass eine Gestensteuerung als Alternative zu einem herkömmlichen Teach Pendant auf Grundlage von ROS mit der Zuhilfenahme eines \quoteMark{WidowX 200}-Lernroboters und einer Azure Kinect implementiert werden kann. Die entwickelten Gesten, welche einerseits unbeabsichtigte Bewegungen nicht zulassen sollen und andererseits zudem Ermüdungserscheinungen entgegen wirken sollen, haben sich während der durchgeführten Tests bewährt. Durch die Roboter-Gesten-Anwendung wurde es einem erfahrenen Probanden ermöglicht ein praxisnahes Teachbeispiel durchzuführen und so einem \quoteMark{WidowX 200}-Lernroboter in angemessener Zeit Zielpositionen beizubringen. Zudem ist es möglich die Zielpositionen in einer Datei zu speichern und daraufhin erneut autonom abspielen zu lassen. Das erstellte Roboter-Gesten-Framework ist modular aufgebaut und kann bei Implementerung der spezifischen Schnittstellen neben dem \quoteMark{WidowX 200}-Lernroboter daher auch mit anderen Industrierobotern zusammenarbeiten und neben der Azure Kinect auch mit anderen Tiefenkameras betrieben werden.\\

Da die Zeit von unter 50 ms, welches für ein Teach Pendant empfohlen wird \cite[55]{prassler_advances_2004}, nicht eingehalten werden kann  muss die Berechnung des neuronalen Netzwerks der Gestenerkennung noch schneller werden bzw. auf speziell darauf ausgelegter Hardware, wie z.B. FPGAs, ausgeführt werden. Zudem wäre es aufgrund der extremen Schwankungen empfehlenswert zeitkritische Steuerungsbefehle mehrmals zu senden um sichergehen zu können, dass diese auch zeitgerecht ankommen. Hierzu müsste jedoch ein Algorithmus implementiert werden um identische Steuerungsbefehle erkennen und ein mehrmaliges Ausführen der Steuerungsbefehle verhindern zu können.\\

Zudem liegt die Latenzzeit der ROS-Kommunikation in einem realitsnahen Gigabit-Ethernet-Netzwerk weit über den maximalen 50 ms, welche für ein Teach Pendant empfohlen werden \cite[55]{prassler_advances_2004}. Selbst bei betrachtung der maximalen Durchschnittlichen Latenzzeit von 116 ms liegt diese noch zu weit über den 100 ms um einer bedienenden Person das Gefühl einer inputlag freien Erfahrung zu vermitteln \cite{miller_response_1968}. Bei der lokalen Interprozesskommunikation über das Loopback-Interface konnte sich die ROS-Kommunikation jedoch beweisen, da die Latenzzeit von Durchschnitt zwischen 23 ms und 36 ms in den meisten echtzeitnahen Anwendungsgebieten ausreichend sein sollte. Es ist jedoch immer noch ein Trade-off zwischen Modularität und Performance. Wenn jedoch die Modularität im Vordergrund steht kann die ROS-Kommunikation über das Loopback-Interface eine Möglichkeit darstellen um die verschiedenen Komponenten des Systems austauschbar zu halten. Das Problem besteht jedoch immer noch in der Tatsache, dass sich die Zeiten für die Gestenerkennung und der Latenzzeit zwischen der Kommunikation mit der InterbotiX-Schnittstelle summieren und dadurch weit über den erwähnten Latenzzeiten liegen. ROS ist daher keine Allzwecklösung für alle Problemstellungen, sondern nur eine mögliche Implementierung die sich erst noch über die Jahre im industriellen Einsatz behaupten muss \cite{why_dont_we_use_ros_nodate}.

\section{Ausblick}
Der CPU-Modus des Azure Kinect Body Tracking SDKs ist mit einer gemessenen Latenz von um die 300 ms nutzbar, jedoch aber zeitkritisch aus sicherheitstechnischer Sicht. Aus diesem Grund ist zu hoffen, dass das Azure Kinect Body Tracking SDK neben der CUDA basierten Grafikkartenbeschleunigung, welche nur auf Nvidia basierten Grafikkarten verfügbar ist \cite{encausse_body_nodate}, eine herstellerunabhängige Implementierung erhält. Als alternative und platformunabhängige Programmierschnittstelle zu CUDA wäre hier z.B. OpenCL oder Vulkan anzumerken \cite{vulkan_api_2020}. Dies würde vor allem die Performanz der Gestenerkennung, die freie Wahl der Rechnerkomponenten ermöglichen und zudem den Wettbewerb zwischen den Herstellern fördern.\\

Im Vergleich zur Kinect 2, welche eine \num{0,3}-Megapixel-Tiefenkamera verbaut hat, ist die Azure Kinect, welche eine 1-Megapixel-Tiefenkamera besitzt, bereits eine deutliche Weiterentwicklung zu ihrem Vorgängermodell. Nichtsdestotrotz ist hier jedoch durch den großen Spring von einer \num{0,3}- auf eine 1-Megapixel-Auflösung noch genügend Verbesserungspotenziall vorhanden um noch höhere Auflösungen erreichen zu können \cite{bamji__2018}. Mit einer höheren Auflösung der Tiefenkamera wäre es möglich die Gesten noch genauer zu erkennen und die False-Positive-Rate noch weiter zu verringern. Mittels Eye-Tracking, welches z.B. in der HoloLens 2 verbaut ist \cite{hololens2_hardware_nodate}, könnte man die Sicherheit der bedienenden Person zusätzlich erhöhen und die Gestenerkennung noch zuverlässiger gestalten. Hiermit könnte man unter anderem erkennen ob die bedienende Person Ermüdungserscheinungen aufweist und daher besser eine Pause einlegen sollte oder sogar nicht mehr bei Bewusstsein ist, da die bedienende Person z.B. ungewollt auf dem Boden liegt. Es wäre zudem denkbar, dass die Umgebung des Industrieroboters durch weitere Tiefenkameras abgescannt werden könnte um eine Kollisionserkennung für den Industrieroboter zu realisieren. Hierdurch könnte der Industrieroboter auf Hindernisse reagieren und so Personen sowie auch anderen Objekte frühzeitig zu erkennen. Dadurch könnte die Sicherheit des Systems höchstwahrscheinlich zusätzlich verbessert werden und die Gefahr von kritischen Situationen nochmals verringert werden. Durch die Verwendung von mehreren im Raum verteilten Tiefenkameras könnten zudem tote Winkel verringert und die Bedienung der Roboter-Gesten-Anwendung aus verschiedenen Blickrichtungen fehlerfreier ermöglicht werden.\\

Weiteres Forschungspotenzial besteht auch im Bereich der Sicherheit und Ergonomie der in dieser Arbeit entwickelten Roboter-Gesten-Anwendung. Hierbei könnte erforscht werden wie gut sich z.B. smarte Fußeinlagesohlen zur Sicherheits- und Ergonomiesteigerung eignen würden. Hierdurch würden die Hände zur Gestensteuerung frei bleiben und es könnte womöglich eine Art von \quoteMark{Dead Man's Switch} mit einer smarten Fußeinlagesohle realisiert werden. Hierdurch wäre es vermutlich machbar sehr schnelle und reflexartige Druckverteilungen und Bewegungen zu Erkennen und den Industrieroboter bei dieser Art von Bewegung zu stoppen. Zu wenig oder kein Druck auf den Fußeinlagesohlen könnten mehrere Gründe haben, da z.B. die Sohlen abgezogen wurden oder die bedienende Person ungewollt auf dem Boden liegt. Das Starten der Gestenerkennung könnte womöglich auch durch eine korrekt ausgeführte Kombination aus Fußbewegungen realisiert werden \cite{tan_design_2015}. Eine andere Möglichkeit würde darin bestehen einen smarten Handschuh mit einem Beschleunigungssensor und einem Gyroskop zu verwenden, welcher zu schnelle Bewegungen erkennen könnte und die Bewegung des Industrieroboters bei auffälligen Bewegungen anhält \cite{ghimire_smart_2019}. Zur Realisierung könnte ein künstliches neuronales Netzwerk auf diese auffälligen Bewegungen trainiert werden.
